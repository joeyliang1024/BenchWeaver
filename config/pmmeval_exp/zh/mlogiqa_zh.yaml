### OpenAI Source
openai_source: "azure"

### inference model
inference_model_name_or_path: google/gemma-3-27b-it
inference_mode: local
cot: false

### checker model
checker_model_name_or_path: Qwen/Qwen2.5-32B-Instruct
check_mode: local

### translation model
translation_model_name_or_path: gpt-4o-mini
translation_mode: api
transation_templates_name: proper_nouns
#### source_lang: 
#### 1. the source language for the translation model
#### 2. the trans pipeline object language
source_lang: zh
target_lang: zh

### source dataset
task: logiqa_test
task_dir: evaluation_data/P-MMEval/zh
# ref_task_dir: null
#### lang: usually the name of the template, set same as your model main language
lang: zh
n_shot: 0
benchmark_mode: mcqa-oq
pipeline: same
batch_size: 4

### reference dataset, split will use 'test' don't specify
# ref_task: mmlu

### output
save_dir: score/pmmeval_exp/zh/mlogiqa/zh

### VLLM 
vllm_maxlen: 8192
vllm_max_concurrency: 30
max_new_tokens: 2048
dtype: float32 # float32
### debug
# testing_size: 5
record_all: true
# print_param_status: false