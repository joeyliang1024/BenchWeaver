### OpenAI Source
openai_source: "azure"

### inference model
inference_model_name_or_path: meta-llama/Llama-3.1-8B-Instruct
inference_mode: local
cot: true

### checker model
checker_model_name_or_path: Qwen/Qwen2.5-32B-Instruct
check_mode: local

### translation model
translation_model_name_or_path: gpt-4o-mini
translation_mode: api
transation_templates_name: mix
source_lang: ko
target_lang: zh-tw

### source dataset
task: tmlu_test 
task_dir: evaluation_data
lang: zh-tw
n_shot: 5
benchmark_mode: mcqa-oq
pipeline: same
batch_size: 4

### reference dataset, split will use 'test' don't specify
# ref_task: mmlu

### output
save_dir: score/tmlu_test

### VLLM 
vllm_maxlen: 10240
vllm_max_concurrency: 30
max_new_tokens: 2048
dtype: float16
### debug
testing_size: 3
record_all: true
# print_param_status: false