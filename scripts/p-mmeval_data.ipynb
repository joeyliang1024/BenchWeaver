{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aba0fd82",
   "metadata": {},
   "source": [
    "# Loading Dataformat\n",
    "the object format:\n",
    "- P-MMeval-EN\n",
    "- P-MMEval-ZH\n",
    "- P-MMEval-KO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b901b069",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from zipfile import ZipFile\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "P_MMEVAL_EN = {}\n",
    "P_MMEVAL_KO = {}\n",
    "P_MMEVAL_ZH = {}\n",
    "\n",
    "object_languages = [\"Chinese\", \"English\", \"Korean\", \"en\", \"zh\", \"ko\", \"mmlu_EN-US\", \"mmlu_KO-KR\", \"mmlu_ZH-CN\"]\n",
    "object_languages_dict = {\n",
    "    \"Chinese\": \"zh\",\n",
    "    \"English\": \"en\",\n",
    "    \"Korean\": \"ko\",\n",
    "    \"en\": \"en\",\n",
    "    \"zh\": \"zh\",\n",
    "    \"ko\": \"ko\",\n",
    "    \"mmlu_EN-US\": \"en\",\n",
    "    \"mmlu_KO-KR\": \"ko\",\n",
    "    \"mmlu_ZH-CN\": \"zh\"\n",
    "}\n",
    "\n",
    "header = '''# coding=utf-8\n",
    "# Copyright 2024 The P-MMEval Authors.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import os\n",
    "from typing import List\n",
    "import datasets\n",
    "import pandas as pd\n",
    "\n",
    "_CITATION = \"\"\"\\\\\n",
    "@misc{zhang2024pmmevalparallelmultilingualmultitask,\n",
    "      title={P-MMEval: A Parallel Multilingual Multitask Benchmark for Consistent Evaluation of LLMs}, \n",
    "      author={Yidan Zhang and Yu Wan and Boyi Deng and Baosong Yang and Haoran Wei and Fei Huang and Bowen Yu and Junyang Lin and Fei Huang and Jingren Zhou},\n",
    "      year={2024},\n",
    "      eprint={2411.09116},\n",
    "      archivePrefix={arXiv},\n",
    "      primaryClass={cs.CL},\n",
    "      url={https://arxiv.org/abs/2411.09116}, \n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "_DESCRIPTION = \"\"\"\\\\\n",
    "We introduce a multilingual benchmark, P-MMEval, covering effective fundamental and capability-specialized datasets. We extend the existing benchmarks, ensuring consistent language coverage across all datasets and providing parallel samples among multiple languages, supporting up to 10 languages from 8 language families (i.e., en, zh, ar, es, ja, ko, th, fr, pt, vi). As a result, P-MMEval facilitates a holistic assessment of multilingual capabilities and comparative analysis of cross-lingual transferability.\n",
    "\"\"\"\n",
    "\n",
    "_HOMEPAGE = \"https://huggingface.co/datasets/Qwen/P-MMEval\"\n",
    "_LICENSE = \"Apache-2.0\"\n",
    "_URL = \"{{name}}.zip\"\n",
    "\n",
    "task_list = [\"all\"]\n",
    "'''\n",
    "\n",
    "\n",
    "def export_files_and_zip(name: str, \n",
    "                         output_dir, \n",
    "                         test_split: List[dict], \n",
    "                         dev_split: List[dict] = None, \n",
    "                         dev_set: bool = False, \n",
    "                         parquet_format: bool = True\n",
    "                         ):\n",
    "    \"\"\"\n",
    "    Export the test split to a zip file.\n",
    "    \"\"\"\n",
    "    if os.path.exists(output_dir):\n",
    "        os.makedirs(os.path.join(output_dir, \"data\"), exist_ok=True)\n",
    "        if test_split:\n",
    "            os.makedirs(os.path.join(output_dir, \"data\", \"test\"), exist_ok=True)\n",
    "        if dev_split and dev_set:\n",
    "            os.makedirs(os.path.join(output_dir, \"data\", \"dev\"), exist_ok=True)\n",
    "        \n",
    "    # export data to csv or parquet\n",
    "    if parquet_format:\n",
    "        test_df = pd.DataFrame(test_split)\n",
    "        test_df.to_parquet(os.path.join(output_dir, \"data\", \"test\", \"all_test.parquet\"), index=False)\n",
    "        if dev_split and dev_set:\n",
    "            dev_df = pd.DataFrame(dev_split)\n",
    "            dev_df.to_parquet(os.path.join(output_dir, \"data\", \"dev\", \"all_dev.parquet\"), index=False)\n",
    "    else:\n",
    "        test_df = pd.DataFrame(test_split)\n",
    "        test_df.to_csv(os.path.join(output_dir, \"data\", \"test\", \"all_test.csv\"), index=False)\n",
    "        if dev_split and dev_set:\n",
    "            dev_df = pd.DataFrame(dev_split)\n",
    "            dev_df.to_csv(os.path.join(output_dir, \"data\", \"dev\", \"all_dev.csv\"), index=False)\n",
    "    mapping = {\n",
    "        \"all\":{\n",
    "            \"name\": \"All\",\n",
    "            \"category\": \"all\",\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(test_df.columns)\n",
    "    with open(os.path.join(output_dir, \"mapping.json\"), 'w') as f:\n",
    "        json.dump(mapping, f, ensure_ascii=False, indent=2)\n",
    "    # create a python file\n",
    "    # with open(os.path.join(output_dir, f\"{name}.py\"), 'w') as f:\n",
    "    #     f.write(header.replace(\"{{name}}\", name))\n",
    "    # zip files in the data directory and renamed to name given\n",
    "    with ZipFile(os.path.join(output_dir, f\"{name}.zip\"), 'w') as zipf:\n",
    "        data_dir = os.path.join(output_dir, \"data\")\n",
    "        for root, dirs, files in os.walk(data_dir):\n",
    "            for file in files:\n",
    "                full_path = os.path.join(root, file)\n",
    "                # Include the 'data/' folder in the archive\n",
    "                arcname = os.path.relpath(full_path, output_dir)\n",
    "                zipf.write(full_path, arcname)\n",
    "    # delete the data directory\n",
    "    import shutil\n",
    "    shutil.rmtree(os.path.join(output_dir, \"data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b15275fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# humaneval-xl\n",
    "humaneval_xl_data_dict = {}\n",
    "for code_name in os.listdir(\"/work/u5110390/BenchWeaver/P-MMEval/humaneval-xl/test\"):\n",
    "    for name in os.listdir(f\"/work/u5110390/BenchWeaver/P-MMEval/humaneval-xl/test/{code_name}\"):\n",
    "        lang = name.split(\".\")[0]\n",
    "        if lang in object_languages:\n",
    "            with open(f\"/work/u5110390/BenchWeaver/P-MMEval/humaneval-xl/test/{code_name}/{name}\", \"r\") as f:\n",
    "                data = []\n",
    "                for line in f:\n",
    "                    line = json.loads(line)\n",
    "                    data.append({\n",
    "                        \"task_id\": line[\"task_id\"],\n",
    "                        \"text\": line[\"prompt\"],\n",
    "                        \"test_list\": [line['test']],\n",
    "                        \"prompt\": line[\"prompt\"],\n",
    "                        \"test\": line['test'],\n",
    "                        \"entry_point\": line[\"entry_point\"],\n",
    "                        \"description\": line[\"description\"],\n",
    "                        \"language\": line[\"language\"],\n",
    "                        \"canonical_solution\": line[\"canonical_solution\"],\n",
    "                        \"declaration\": line[\"declaration\"],\n",
    "                    })\n",
    "            if lang not in humaneval_xl_data_dict.keys():\n",
    "                humaneval_xl_data_dict[lang] = data\n",
    "            else:\n",
    "                humaneval_xl_data_dict[lang] += data\n",
    "\n",
    "# Update the P-MMEval dictionaries\n",
    "for lang in humaneval_xl_data_dict.keys():\n",
    "    unify_lang = object_languages_dict[lang]\n",
    "    if unify_lang == \"en\":\n",
    "        P_MMEVAL_EN[\"humaneval-xl\"] = humaneval_xl_data_dict[lang]\n",
    "    elif unify_lang == \"ko\":\n",
    "        P_MMEVAL_KO[\"humaneval-xl\"] = humaneval_xl_data_dict[lang]\n",
    "    elif unify_lang == \"zh\":\n",
    "        P_MMEVAL_ZH[\"humaneval-xl\"] = humaneval_xl_data_dict[lang]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa655185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mgsm\n",
    "mgsm_data_test_dict = {}\n",
    "for name in os.listdir(\"/work/u5110390/BenchWeaver/P-MMEval/mgsm/test\"):\n",
    "    lang = name.split(\".\")[0]\n",
    "    if lang in object_languages:\n",
    "        with open(f\"/work/u5110390/BenchWeaver/P-MMEval/mgsm/test/{lang}.jsonl\", \"r\") as f:\n",
    "            data = []\n",
    "            for line in f:\n",
    "                line = json.loads(line)\n",
    "                data.append(line)\n",
    "        mgsm_data_test_dict[lang] = data\n",
    "\n",
    "# Update the P-MMEval dictionaries\n",
    "for lang in mgsm_data_test_dict.keys():\n",
    "    unify_lang = object_languages_dict[lang]\n",
    "    if unify_lang == \"en\":\n",
    "        P_MMEVAL_EN[\"mgsm\"] = mgsm_data_test_dict[lang]\n",
    "    elif unify_lang == \"ko\":\n",
    "        P_MMEVAL_KO[\"mgsm\"] = mgsm_data_test_dict[lang]\n",
    "    elif unify_lang == \"zh\":\n",
    "        P_MMEVAL_ZH[\"mgsm\"] = mgsm_data_test_dict[lang]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "063211bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mhellaswag\n",
    "mhellaswag_data_test_dict = {}\n",
    "\n",
    "for name in os.listdir(\"/work/u5110390/BenchWeaver/P-MMEval/mhellaswag/test\"):\n",
    "    lang = name.split(\".\")[0]\n",
    "    if lang in object_languages:\n",
    "        with open(f\"/work/u5110390/BenchWeaver/P-MMEval/mhellaswag/test/{lang}.jsonl\", \"r\") as f:\n",
    "            data = []\n",
    "            for line in f:\n",
    "                line = json.loads(line)\n",
    "                data.append({\n",
    "                    \"activity_label\": line[\"activity_label\"],\n",
    "                    \"split_type\": line[\"split\"],\n",
    "                    \"question\": line['ctx'],\n",
    "                    \"A\": line[\"endings\"][0],\n",
    "                    \"B\": line[\"endings\"][1],\n",
    "                    \"C\": line[\"endings\"][2],\n",
    "                    \"D\": line[\"endings\"][3],\n",
    "                    \"answer\": chr(ord('A') + int(line['label'])),\n",
    "                    })\n",
    "        mhellaswag_data_test_dict[lang] = data\n",
    "\n",
    "# Update the P-MMEval dictionaries\n",
    "for lang in mhellaswag_data_test_dict.keys():\n",
    "    unify_lang = object_languages_dict[lang]\n",
    "    if unify_lang == \"en\":\n",
    "        P_MMEVAL_EN[\"mhellaswag\"] = mhellaswag_data_test_dict[lang]\n",
    "    elif unify_lang == \"ko\":\n",
    "        P_MMEVAL_KO[\"mhellaswag\"] = mhellaswag_data_test_dict[lang]\n",
    "    elif unify_lang == \"zh\":\n",
    "        P_MMEVAL_ZH[\"mhellaswag\"] = mhellaswag_data_test_dict[lang]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecb4d845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mifeval\n",
    "mifeval_data_test_dict = {}\n",
    "\n",
    "for name in os.listdir(\"/work/u5110390/BenchWeaver/P-MMEval/mifeval/test\"):\n",
    "    lang = name.split(\".\")[0]\n",
    "    if lang in object_languages:\n",
    "        with open(f\"/work/u5110390/BenchWeaver/P-MMEval/mifeval/test/{lang}.jsonl\", \"r\") as f:\n",
    "            data = []\n",
    "            for line in f:\n",
    "                line = json.loads(line)\n",
    "                data.append({\n",
    "                    \"key\": line[\"key\"], \n",
    "                    \"question\": line['prompt'], \n",
    "                    \"instruction_id_list\": line['instruction_id_list'], \n",
    "                    \"kwargs\": line['kwargs'],\n",
    "                             })\n",
    "        mifeval_data_test_dict[lang] = data\n",
    "\n",
    "# Update the P-MMEval dictionaries\n",
    "for lang in mifeval_data_test_dict.keys():\n",
    "    unify_lang = object_languages_dict[lang]\n",
    "    if unify_lang == \"en\":\n",
    "        P_MMEVAL_EN[\"mifeval\"] = mifeval_data_test_dict[lang]\n",
    "    elif unify_lang == \"ko\":\n",
    "        P_MMEVAL_KO[\"mifeval\"] = mifeval_data_test_dict[lang]\n",
    "    elif unify_lang == \"zh\":\n",
    "        P_MMEVAL_ZH[\"mifeval\"] = mifeval_data_test_dict[lang]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "424f48bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlogiqa\n",
    "\n",
    "mlogiqa_data_test_dict = {}\n",
    "\n",
    "for name in os.listdir(\"/work/u5110390/BenchWeaver/P-MMEval/mlogiqa/test\"):\n",
    "    lang = name.split(\".\")[0]\n",
    "    if lang in object_languages:\n",
    "        with open(f\"/work/u5110390/BenchWeaver/P-MMEval/mlogiqa/test/{lang}.jsonl\", \"r\") as f:\n",
    "            data = []\n",
    "            for line in f:\n",
    "                line = json.loads(line)\n",
    "                data.append({\n",
    "                    \"question\": line['question'],\n",
    "                    \"context\": line['context'],\n",
    "                    \"A\": line[\"options\"][0],\n",
    "                    \"B\": line[\"options\"][1],\n",
    "                    \"C\": line[\"options\"][2],\n",
    "                    \"D\": line[\"options\"][3],\n",
    "                    \"answer\": chr(ord('A') + int(line['answer'])),\n",
    "                    })\n",
    "        mlogiqa_data_test_dict[lang] = data\n",
    "\n",
    "# Update the P-MMEval dictionaries\n",
    "for lang in mlogiqa_data_test_dict.keys():\n",
    "    unify_lang = object_languages_dict[lang]\n",
    "    if unify_lang == \"en\":\n",
    "        P_MMEVAL_EN[\"mlogiqa\"] = mlogiqa_data_test_dict[lang]\n",
    "    elif unify_lang == \"ko\":\n",
    "        P_MMEVAL_KO[\"mlogiqa\"] = mlogiqa_data_test_dict[lang]\n",
    "    elif unify_lang == \"zh\":\n",
    "        P_MMEVAL_ZH[\"mlogiqa\"] = mlogiqa_data_test_dict[lang]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "737f132a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mmmlu\n",
    "mmmlu_data_test_dict = {}\n",
    "mmmlu_data_dev_dict = {}\n",
    "for name in os.listdir(\"/work/u5110390/BenchWeaver/P-MMEval/mmmlu/easy/test\"):\n",
    "    lang = name.split(\".\")[0]\n",
    "    if lang in object_languages:\n",
    "        with open(f\"/work/u5110390/BenchWeaver/P-MMEval/mmmlu/easy/test/{lang}.jsonl\", \"r\") as f:\n",
    "            data = []\n",
    "            for line in f:\n",
    "                line = json.loads(line)\n",
    "                data.append({\n",
    "                    \"difficulty\": \"easy\",\n",
    "                    \"question\": line['Question'],\n",
    "                    \"A\": line[\"A\"],\n",
    "                    \"B\": line[\"B\"],\n",
    "                    \"C\": line[\"C\"],\n",
    "                    \"D\": line[\"D\"],\n",
    "                    \"answer\": line['Answer'],\n",
    "                    \"subject\": line['Subject'],\n",
    "                })\n",
    "        mmmlu_data_test_dict[lang] = data\n",
    "        \n",
    "for name in os.listdir(\"/work/u5110390/BenchWeaver/P-MMEval/mmmlu/hard/test\"):\n",
    "    lang = name.split(\".\")[0]\n",
    "    if lang in object_languages:\n",
    "        with open(f\"/work/u5110390/BenchWeaver/P-MMEval/mmmlu/hard/test/{lang}.jsonl\", \"r\") as f:\n",
    "            data = []\n",
    "            for line in f:\n",
    "                line = json.loads(line)\n",
    "                data.append({\n",
    "                    \"difficulty\": \"hard\",\n",
    "                    \"question\": line['Question'],\n",
    "                    \"A\": line[\"A\"],\n",
    "                    \"B\": line[\"B\"],\n",
    "                    \"C\": line[\"C\"],\n",
    "                    \"D\": line[\"D\"],\n",
    "                    \"answer\": line['Answer'],\n",
    "                    \"subject\": line['Subject'],\n",
    "                })\n",
    "        mmmlu_data_test_dict[lang] += data\n",
    "\n",
    "for name in os.listdir(\"/work/u5110390/BenchWeaver/P-MMEval/mmmlu/val\"):\n",
    "    lang = name.split(\".\")[0]\n",
    "    if lang in object_languages:\n",
    "        with open(f\"/work/u5110390/BenchWeaver/P-MMEval/mmmlu/val/{lang}.jsonl\", \"r\") as f:\n",
    "            data = []\n",
    "            for line in f:\n",
    "                line = json.loads(line)\n",
    "                data.append({\n",
    "                    \"difficulty\": \"\",\n",
    "                    \"question\": line['Question'],\n",
    "                    \"A\": line[\"A\"],\n",
    "                    \"B\": line[\"B\"],\n",
    "                    \"C\": line[\"C\"],\n",
    "                    \"D\": line[\"D\"],\n",
    "                    \"answer\": line['Answer'],\n",
    "                    \"subject\": line['Subject'],\n",
    "                })\n",
    "        unify_lang = object_languages_dict[lang]\n",
    "        mmmlu_data_dev_dict[unify_lang] = data\n",
    "\n",
    "# Update the P-MMEval dictionaries\n",
    "for lang in mmmlu_data_test_dict.keys():\n",
    "    unify_lang = object_languages_dict[lang]\n",
    "    if unify_lang == \"en\":\n",
    "        P_MMEVAL_EN[\"mmmlu\"] = mmmlu_data_test_dict[lang]\n",
    "    elif unify_lang == \"ko\":\n",
    "        P_MMEVAL_KO[\"mmmlu\"] = mmmlu_data_test_dict[lang]\n",
    "    elif unify_lang == \"zh\":\n",
    "        P_MMEVAL_ZH[\"mmmlu\"] = mmmlu_data_test_dict[lang]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7b6eafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xnli\n",
    "xnli_data_test_dict = {}\n",
    "for name in os.listdir(\"/work/u5110390/BenchWeaver/P-MMEval/xnli/test\"):\n",
    "    lang = name.split(\".\")[0]\n",
    "    if lang in object_languages:\n",
    "        with open(f\"/work/u5110390/BenchWeaver/P-MMEval/xnli/test/{lang}.jsonl\", \"r\") as f:\n",
    "            data = []\n",
    "            for line in f:\n",
    "                line = json.loads(line)\n",
    "                data.append({\n",
    "                    \"premise\": line['premise'],\n",
    "                    \"statement\": line['statement'],\n",
    "                    \"answer\": line['answer'],\n",
    "                })\n",
    "        xnli_data_test_dict[lang] = data\n",
    "\n",
    "# Update the P-MMEval dictionaries\n",
    "for lang in xnli_data_test_dict.keys():\n",
    "    unify_lang = object_languages_dict[lang]\n",
    "    if unify_lang == \"en\":\n",
    "        P_MMEVAL_EN[\"xnli\"] = xnli_data_test_dict[lang]\n",
    "    elif unify_lang == \"ko\":\n",
    "        P_MMEVAL_KO[\"xnli\"] = xnli_data_test_dict[lang]\n",
    "    elif unify_lang == \"zh\":\n",
    "        P_MMEVAL_ZH[\"xnli\"] = xnli_data_test_dict[lang]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716bdb7a",
   "metadata": {},
   "source": [
    "# Exports Datasets\n",
    "- we only need the average score of the P-MMeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2052e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['humaneval-xl'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_MMEVAL_EN.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9667a09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting humaneval-xl...\n",
      "Index(['task_id', 'text', 'test_list', 'prompt', 'test', 'entry_point',\n",
      "       'description', 'language', 'canonical_solution', 'declaration'],\n",
      "      dtype='object')\n",
      "Exporting humaneval-xl... done\n"
     ]
    }
   ],
   "source": [
    "for benchmark_name, language_split in P_MMEVAL_EN.items():\n",
    "    print(f\"Exporting {benchmark_name}...\")\n",
    "    export_files_and_zip(\n",
    "        benchmark_name, \n",
    "        f\"/work/u5110390/BenchWeaver/evaluation_data/P-MMEval/en/{benchmark_name}\", \n",
    "        language_split, \n",
    "        dev_split=mmmlu_data_dev_dict[\"en\"] if benchmark_name == \"mmmlu\" else None, \n",
    "        dev_set=True if benchmark_name == \"mmmlu\" else False, \n",
    "        parquet_format=True\n",
    "        )\n",
    "    print(f\"Exporting {benchmark_name}... done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c125e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting humaneval-xl...\n",
      "Index(['task_id', 'text', 'test_list', 'prompt', 'test', 'entry_point',\n",
      "       'description', 'language', 'canonical_solution', 'declaration'],\n",
      "      dtype='object')\n",
      "Exporting humaneval-xl... done\n"
     ]
    }
   ],
   "source": [
    "for benchmark_name, language_split in P_MMEVAL_ZH.items():\n",
    "    print(f\"Exporting {benchmark_name}...\")\n",
    "    export_files_and_zip(\n",
    "        benchmark_name, \n",
    "        f\"/work/u5110390/BenchWeaver/evaluation_data/P-MMEval/zh/{benchmark_name}\", \n",
    "        language_split, \n",
    "        dev_split=mmmlu_data_dev_dict[\"zh\"] if benchmark_name == \"mmmlu\" else None, \n",
    "        dev_set=True if benchmark_name == \"mmmlu\" else False, \n",
    "        parquet_format=True \n",
    "        )\n",
    "    print(f\"Exporting {benchmark_name}... done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8cc634b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting humaneval-xl...\n",
      "Index(['task_id', 'text', 'test_list', 'prompt', 'test', 'entry_point',\n",
      "       'description', 'language', 'canonical_solution', 'declaration'],\n",
      "      dtype='object')\n",
      "Exporting humaneval-xl... done\n"
     ]
    }
   ],
   "source": [
    "for benchmark_name, language_split in P_MMEVAL_KO.items():\n",
    "    print(f\"Exporting {benchmark_name}...\")\n",
    "    export_files_and_zip(\n",
    "        benchmark_name, \n",
    "        f\"/work/u5110390/BenchWeaver/evaluation_data/P-MMEval/ko/{benchmark_name}\", \n",
    "        language_split, \n",
    "        dev_split=mmmlu_data_dev_dict[\"ko\"] if benchmark_name == \"mmmlu\" else None, \n",
    "        dev_set=True if benchmark_name == \"mmmlu\" else False, \n",
    "        parquet_format=True\n",
    "        )\n",
    "    print(f\"Exporting {benchmark_name}... done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BenchWeaver",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
