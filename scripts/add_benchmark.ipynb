{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLIcK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>question</th>\n",
       "      <th>choices</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KIIP_economy_1</td>\n",
       "      <td></td>\n",
       "      <td>다음은 한국 사회의 경제에 대한 문제이다.\\n한국이 외환위기를 완전히 극복한 년도는...</td>\n",
       "      <td>[1999년, 2000년, 2001년, 2002년]</td>\n",
       "      <td>2001년</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KIIP_economy_2</td>\n",
       "      <td></td>\n",
       "      <td>다음은 한국 사회의 경제에 대한 문제이다.\\n1960년 한국의 1인당 국민총소득은 ...</td>\n",
       "      <td>[79달러, 800달러, 8,000달러, 80,000달러]</td>\n",
       "      <td>79달러</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KIIP_economy_3</td>\n",
       "      <td></td>\n",
       "      <td>다음은 한국 사회의 경제에 대한 문제이다.\\n한국이 외환위기를 겪은 년도는 언제인가?</td>\n",
       "      <td>[1995년, 1996년, 1997년, 1998년]</td>\n",
       "      <td>1997년</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KIIP_economy_4</td>\n",
       "      <td></td>\n",
       "      <td>다음은 한국 사회의 경제에 대한 문제이다.\\n한강은 어느 도시를 통과하는가?</td>\n",
       "      <td>[부산, 대구, 인천, 서울]</td>\n",
       "      <td>서울</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KIIP_economy_5</td>\n",
       "      <td></td>\n",
       "      <td>다음은 한국 사회의 경제에 대한 문제이다.\\n1970년대부터 한국에서 발달하기 시작...</td>\n",
       "      <td>[농업, 경공업, 중화학 공업, 서비스 업]</td>\n",
       "      <td>중화학 공업</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id paragraph  \\\n",
       "0  KIIP_economy_1             \n",
       "1  KIIP_economy_2             \n",
       "2  KIIP_economy_3             \n",
       "3  KIIP_economy_4             \n",
       "4  KIIP_economy_5             \n",
       "\n",
       "                                            question  \\\n",
       "0  다음은 한국 사회의 경제에 대한 문제이다.\\n한국이 외환위기를 완전히 극복한 년도는...   \n",
       "1  다음은 한국 사회의 경제에 대한 문제이다.\\n1960년 한국의 1인당 국민총소득은 ...   \n",
       "2    다음은 한국 사회의 경제에 대한 문제이다.\\n한국이 외환위기를 겪은 년도는 언제인가?   \n",
       "3         다음은 한국 사회의 경제에 대한 문제이다.\\n한강은 어느 도시를 통과하는가?   \n",
       "4  다음은 한국 사회의 경제에 대한 문제이다.\\n1970년대부터 한국에서 발달하기 시작...   \n",
       "\n",
       "                            choices  answer  \n",
       "0      [1999년, 2000년, 2001년, 2002년]   2001년  \n",
       "1  [79달러, 800달러, 8,000달러, 80,000달러]    79달러  \n",
       "2      [1995년, 1996년, 1997년, 1998년]   1997년  \n",
       "3                  [부산, 대구, 인천, 서울]      서울  \n",
       "4          [농업, 경공업, 중화학 공업, 서비스 업]  중화학 공업  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from typing import Tuple\n",
    "import pandas as pd\n",
    "\n",
    "ds = load_dataset(\"EunsuKim/CLIcK\")\n",
    "df = ds['train'].to_pandas()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_category(id_text: str) -> str:\n",
    "    text_split = id_text.split('_')\n",
    "    return text_split[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PSAT', 'KHB', 'Kedu', 'PSE', 'KIIP', 'TK', 'CSAT'}\n"
     ]
    }
   ],
   "source": [
    "df['categories'] = df['id'].apply(lambda x: extract_category(x))\n",
    "df['choices'] = df['choices'].apply(lambda x: [str(_) for _ in list(x)])\n",
    "print(set(df['categories']))\n",
    "\n",
    "keys = list(set(df['categories']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1999년', '2000년', '2001년', '2002년']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['choices'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['paragraph', 'question', 'choices', 'answer', 'categories']]\n",
    "dfs = df.groupby('categories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph</th>\n",
       "      <th>question</th>\n",
       "      <th>choices</th>\n",
       "      <th>answer</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1690</th>\n",
       "      <td></td>\n",
       "      <td>( )에 들어갈 가장 알맞은 것을 고르십시오.\\n내일 친구와 함께 놀이공원에 ( ).</td>\n",
       "      <td>[가는 편이다, 가는 중이다, 가기로 했다, 간 적이 있다]</td>\n",
       "      <td>가기로 했다</td>\n",
       "      <td>TK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1691</th>\n",
       "      <td></td>\n",
       "      <td>( )에 들어갈 가장 알맞은 것을 고르십시오.\\n혼자 살다 보니 시간이 ( ) 가족...</td>\n",
       "      <td>[지나거나, 지나도록, 지나거든, 지날수록]</td>\n",
       "      <td>지날수록</td>\n",
       "      <td>TK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1692</th>\n",
       "      <td></td>\n",
       "      <td>다음 괄호 안 부분과 의미가 비슷한 것을 고르십시오.\\n아침에 늦게 (일어나는 바람...</td>\n",
       "      <td>[일어난 탓에, 일어난 김에, 일어나는 대신, 일어나는 대로]</td>\n",
       "      <td>일어난 탓에</td>\n",
       "      <td>TK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1693</th>\n",
       "      <td></td>\n",
       "      <td>다음 괄호 안 부분과 의미가 비슷한 것을 고르십시오.\\n경기에서 이기고 지는 것은 ...</td>\n",
       "      <td>[연습할 따름이다, 연습할 모양이다, 연습하기 나름이다, 연습하기 십상이다]</td>\n",
       "      <td>연습하기 나름이다</td>\n",
       "      <td>TK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1694</th>\n",
       "      <td></td>\n",
       "      <td>(  )에 들어갈 가장 알맞은 것을 고르십시오.\\n해가 뜨는 것을 (  ) 아침 일...</td>\n",
       "      <td>[보아야, 보려고, 보거나, 보는데]</td>\n",
       "      <td>보려고</td>\n",
       "      <td>TK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>올해 서른두 살인 준은 어렸을 때부터 특출나게 뛰어난 재능이 없다는 점이 큰 불만이...</td>\n",
       "      <td>다음 글의 내용으로 알 수 있는 것을 고르십시오.</td>\n",
       "      <td>[준은 여행지에서 해 뜨는 방향을 한 번에 찾았다., 준의 부모님은 아들과 같은 능...</td>\n",
       "      <td>준은 여행지에서 해 뜨는 방향을 한 번에 찾았다.</td>\n",
       "      <td>TK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>서양 역사에서는 15ㆍ16세기를 ‘위대한 발견의 시대’라고 부른다. 콜럼버스 처럼 ...</td>\n",
       "      <td>( )에 들어갈 말로 가장 알맞은 것을 고르십시오.</td>\n",
       "      <td>[값비싼 물건을 매매했기, 다양한 지도를 수집했기, 미지의 땅을 찾아 떠났기, 탐험...</td>\n",
       "      <td>미지의 땅을 찾아 떠났기</td>\n",
       "      <td>TK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>서양 역사에서는 15ㆍ16세기를 ‘위대한 발견의 시대’라고 부른다. 콜럼버스 처럼 ...</td>\n",
       "      <td>다음 글의 주제로 가장 알맞은 것을 고르십시오.</td>\n",
       "      <td>[콜럼버스는 새로운 대륙을 개척하는 데 기여한 바가 크다., 신대륙 발견은 동방의 ...</td>\n",
       "      <td>유럽인들의 탐험은 항로를 만들어 세계를 연결시켰다는 데 의의가 있다.</td>\n",
       "      <td>TK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>세계는 신에너지, 자동화, 우주여행 등이 주도하는 시대로 급속히 접어들고 있다. 세...</td>\n",
       "      <td>다음 글에 나타난 필자의 태도로 가장 알맞은 것을 고르십시오.</td>\n",
       "      <td>[과학 정책에 대한 정부의 지나친 개입을 경계하고 있다., 과학 기술 발전을 위해서...</td>\n",
       "      <td>과학 정책에 대한 정부의 지나친 개입을 경계하고 있다.</td>\n",
       "      <td>TK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>세계는 신에너지, 자동화, 우주여행 등이 주도하는 시대로 급속히 접어들고 있다. 세...</td>\n",
       "      <td>다음 글의 내용과 같은 것을 고르십시오.</td>\n",
       "      <td>[많은 국가들이 신에너지 개발에 대한 투자를 줄이고 있다., 과학 정책이 빠르게 변...</td>\n",
       "      <td>정부가 우주 산업에 대한 규제를 풀어 성장한 민간 기업이 있다.</td>\n",
       "      <td>TK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>237 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              paragraph  \\\n",
       "1690                                                      \n",
       "1691                                                      \n",
       "1692                                                      \n",
       "1693                                                      \n",
       "1694                                                      \n",
       "...                                                 ...   \n",
       "1990  올해 서른두 살인 준은 어렸을 때부터 특출나게 뛰어난 재능이 없다는 점이 큰 불만이...   \n",
       "1991  서양 역사에서는 15ㆍ16세기를 ‘위대한 발견의 시대’라고 부른다. 콜럼버스 처럼 ...   \n",
       "1992  서양 역사에서는 15ㆍ16세기를 ‘위대한 발견의 시대’라고 부른다. 콜럼버스 처럼 ...   \n",
       "1993  세계는 신에너지, 자동화, 우주여행 등이 주도하는 시대로 급속히 접어들고 있다. 세...   \n",
       "1994  세계는 신에너지, 자동화, 우주여행 등이 주도하는 시대로 급속히 접어들고 있다. 세...   \n",
       "\n",
       "                                               question  \\\n",
       "1690    ( )에 들어갈 가장 알맞은 것을 고르십시오.\\n내일 친구와 함께 놀이공원에 ( ).   \n",
       "1691  ( )에 들어갈 가장 알맞은 것을 고르십시오.\\n혼자 살다 보니 시간이 ( ) 가족...   \n",
       "1692  다음 괄호 안 부분과 의미가 비슷한 것을 고르십시오.\\n아침에 늦게 (일어나는 바람...   \n",
       "1693  다음 괄호 안 부분과 의미가 비슷한 것을 고르십시오.\\n경기에서 이기고 지는 것은 ...   \n",
       "1694  (  )에 들어갈 가장 알맞은 것을 고르십시오.\\n해가 뜨는 것을 (  ) 아침 일...   \n",
       "...                                                 ...   \n",
       "1990                        다음 글의 내용으로 알 수 있는 것을 고르십시오.   \n",
       "1991                       ( )에 들어갈 말로 가장 알맞은 것을 고르십시오.   \n",
       "1992                         다음 글의 주제로 가장 알맞은 것을 고르십시오.   \n",
       "1993                 다음 글에 나타난 필자의 태도로 가장 알맞은 것을 고르십시오.   \n",
       "1994                             다음 글의 내용과 같은 것을 고르십시오.   \n",
       "\n",
       "                                                choices  \\\n",
       "1690                  [가는 편이다, 가는 중이다, 가기로 했다, 간 적이 있다]   \n",
       "1691                           [지나거나, 지나도록, 지나거든, 지날수록]   \n",
       "1692                 [일어난 탓에, 일어난 김에, 일어나는 대신, 일어나는 대로]   \n",
       "1693         [연습할 따름이다, 연습할 모양이다, 연습하기 나름이다, 연습하기 십상이다]   \n",
       "1694                               [보아야, 보려고, 보거나, 보는데]   \n",
       "...                                                 ...   \n",
       "1990  [준은 여행지에서 해 뜨는 방향을 한 번에 찾았다., 준의 부모님은 아들과 같은 능...   \n",
       "1991  [값비싼 물건을 매매했기, 다양한 지도를 수집했기, 미지의 땅을 찾아 떠났기, 탐험...   \n",
       "1992  [콜럼버스는 새로운 대륙을 개척하는 데 기여한 바가 크다., 신대륙 발견은 동방의 ...   \n",
       "1993  [과학 정책에 대한 정부의 지나친 개입을 경계하고 있다., 과학 기술 발전을 위해서...   \n",
       "1994  [많은 국가들이 신에너지 개발에 대한 투자를 줄이고 있다., 과학 정책이 빠르게 변...   \n",
       "\n",
       "                                      answer categories  \n",
       "1690                                  가기로 했다         TK  \n",
       "1691                                    지날수록         TK  \n",
       "1692                                  일어난 탓에         TK  \n",
       "1693                               연습하기 나름이다         TK  \n",
       "1694                                     보려고         TK  \n",
       "...                                      ...        ...  \n",
       "1990             준은 여행지에서 해 뜨는 방향을 한 번에 찾았다.         TK  \n",
       "1991                           미지의 땅을 찾아 떠났기         TK  \n",
       "1992  유럽인들의 탐험은 항로를 만들어 세계를 연결시켰다는 데 의의가 있다.         TK  \n",
       "1993          과학 정책에 대한 정부의 지나친 개입을 경계하고 있다.         TK  \n",
       "1994     정부가 우주 산업에 대한 규제를 풀어 성장한 민간 기업이 있다.         TK  \n",
       "\n",
       "[237 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs.get_group('TK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save each group to folder with name: category_test.csv\n",
    "folder = \"/home/joeyliang/BenchWeaver/evaluation_data/click/data/test\"\n",
    "import os\n",
    "for key in keys:\n",
    "    group = dfs.get_group(key)\n",
    "    group.to_csv(os.path.join(folder, f\"{key}_test.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HAE_RAE_BENCH 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, get_dataset_config_names\n",
    "from typing import Tuple\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "opqa = ['lyrics_denoising', 'proverbs_denoising']\n",
    "mcqa = ['correct_definition_matching', 'csat_geo', 'csat_law', 'csat_socio', 'date_understanding', 'general_knowledge', 'history', 'loan_words', 'rare_words', 'standard_nomenclature', 'reading_comprehension']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:17<00:00,  1.61s/it, reading_comprehension]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'(D)', '(E)', '(A)', '(B)', '(C)'}\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# check options for each task\n",
    "import ast\n",
    "from tqdm.auto import  tqdm\n",
    "answers = []\n",
    "with  tqdm(total=len(mcqa)) as pbar:\n",
    "    for task in mcqa:\n",
    "        pbar.set_postfix_str(task)\n",
    "        ds = load_dataset(\"HAERAE-HUB/HAE_RAE_BENCH_1.1\", task)\n",
    "        df = ds['test'].to_pandas()\n",
    "        answers.extend(df['answer'].tolist())\n",
    "        for idx in range(df.shape[0]):\n",
    "            try:\n",
    "                option_list = ast.literal_eval(df['options'].iloc[idx])\n",
    "            except:\n",
    "                option_list = df['options'].iloc[idx].split(\"|\")\n",
    "            if len(option_list) != 5:\n",
    "                print(idx, df['options'].iloc[idx])\n",
    "        pbar.update(1)\n",
    "print(set(answers))\n",
    "print(len(set(answers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 1/11 [00:04<00:41,  4.11s/it, csat_geo]                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------correct_definition_matching-------------------\n",
      "다음 문장에서 \"가노\"가 사용된 의미로 옳은 것을 고르시요. \n",
      "    \n",
      "### 문장: \n",
      "이미 타계한 지 오래인 그의 조부가 서유하 씨 부친이었던 대지주 서 참봉 댁 가노로 있었다.\n",
      "\n",
      "### 선택지: \n",
      "(A) 일본 중부 지방의 중앙부에 있는 현. 제사업, 정밀 기계, 전기 기계 따위의 산업이 발달하였으며, 쌀 및 고랭지 채소의 산지로 알려져 있다. 사과, 배, 포도 따위의 과일도 많이 난다. 현청 소재지는 나가노, 면적은 1만 3633㎢.\n",
      "(B) 16세기에서 17세기 사이의 제정 러시아의 부호 집안. 16세기 중반 이반 사세(Ivan四世)의 신임을 얻으면서부터 융성하여 광대한 직할령, 제염, 제철 따위의 특권을 부여받고 사병(私兵)ㆍ요새의 소유도 인정받았으며 시베리아의 개척에 공헌하였다.\n",
      "(C) 이탈리아의 무용가ㆍ안무가(1769~1821). 발레를 춤추는 드라마로 끌어올린 혁신적인 안무가였다. 베토벤이 그를 위하여 작곡한 <프로메테의 창조물>의 안무가 유명하다.\n",
      "(D) ‘가내 노비’를 줄여 이르는 말.\n",
      "(E) 일본 나가노현 북부에 있는 시. 인쇄, 식료품, 전기 기기 따위의 공업과 상업이 발달하였다. 교외에서는 사과, 야채 따위의 재배가 활발하다. 현청 소재지이다.\n",
      "\n",
      "### 정답:\n",
      "=================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 2/11 [00:05<00:21,  2.44s/it, csat_law]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------csat_geo-------------------\n",
      "다음 자료는 대동여지도 제작에 관한 가상 대화 장면이다. (ㄱ)~(ㄹ)에 대한 옳은 설명만을 <보기>에서 있는 대로 고른 것은?\n",
      "\n",
      "### 참고:\n",
      "<word start>(ㄱ)산줄기<word end>는 끊어지지 않게 하고, 물줄기는 <word start>(ㄴ)쌍선<word end>과 단선으로 구분해서 새기도록 하여라.\n",
      "예. 도로에는 <word start>(ㄷ)방점<word end>도 표시하겠습니다. 그런데 <word start>(ㄹ)목판<word end>에 새기자니 시간이 많이 걸리네요.\n",
      "\n",
      "<보기>\n",
      "(A). (ㄱ)은 하천 유역을 나누는 경계가 된다.\n",
      "(B). (ㄴ)은 배가 다닐 수 있는 하천을 나타낸 것이다.\n",
      "(C). (ㄷ)은 교통 및 통신 시설을 표현한 기호이다.\n",
      "(D). (ㄹ)로 제작되어 지도의 대량 생산이 가능하다.\n",
      "### 선택지: (A)  (A), (B)  (B)  (C), (D)  (C)  (A), (B), (C)  (D)  (A), (B), (D)  (E)  (B), (C), (D)\n",
      "=================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 3/11 [00:06<00:15,  1.93s/it, csat_socio]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------csat_law-------------------\n",
      "다음 자료에 대한 옳은 설명만을 <보기>에서 고른 것은?\n",
      "### 참고:\n",
      "[게임의 규칙]\n",
      "◦ 각 모둠은 (가) ~ (라) 사례 중 서로 다른 두 가지를 선택한다.\n",
      "◦ 선택한 사례가 범죄의 구성 요건에 해당하지 않으면 3점, 위법성 조각 사유에 해당하면 2점, 책임 조각 사유에 해당하면 1점을 획득한다.\n",
      "◦ 범죄가 성립하는 사례를 선택하면 점수를 획득하지 못한다.\n",
      "◦ 선택한 두 사례로 획득한 총점이 가장 높은 모둠이 우승한다.\n",
      "[사례]\n",
      "(가) 갑(14세)은 동급생을 위협하여 금품을 빼앗았다.\n",
      "(나) 을(22세)은 음식점에서 남의 것이라고 생각하고 지갑을 훔쳤는데 알고 보니 자신의 지갑이었다.\n",
      "(다) 병(25세)은 자신의 집에 침입하여 생명을 위협하는 강도를 제압하는 과정에서 강도에게 가벼운 상처를 입혔다.\n",
      "(라) 정(30세)은 심신 상실의 상태에서 행인에게 폭행을 가하였다.\n",
      "<모둠별 선택 결과>\n",
      "\\begin{table}[]\n",
      "\\begin{tabular}{lllll}\n",
      "모둠    & A 모둠     & B 모둠     & C 모둠     & D 모둠     \\\\\n",
      "선택 결과 & (가), (나) & (가), (다) & (나), (다) & (다), (라)\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "<보기>\n",
      "ㄱ. B 모둠의 총점이 가장 낮다.\n",
      "ㄴ. 우승한 모둠은 C 모둠이다.\n",
      "ㄷ. A 모둠의 총점은 D 모둠의 총점보다 높다.\n",
      "ㄹ. 두 가지 사례로 획득할 수 있는 총점은 최대 6점이다.\n",
      "\n",
      "### 선택지: (A) ㄱ, ㄴ (B) ㄱ, ㄷ (C) ㄴ, ㄷ (D) ㄴ, ㄹ (E) ㄷ, ㄹ\n",
      "=================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 4/11 [00:07<00:11,  1.67s/it, date_understanding]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------csat_socio-------------------\n",
      "밑줄 친 (ㄱ) ～ (ㅅ)에 대한 설명으로 옳은 것은? \n",
      "### 참고:\n",
      "연구자 갑은 ‘고등학생의 <word>(ㄱ) 학업 성취도<word/>에 <word>(ㄴ) 꾸준한 운동<word/>이 미치는 영향’을 <word>(ㄷ) 연구 주제로 설정<word/>하고, 고등학생의 학업 성취도에 꾸준한 운동이 긍정적인 효과가 있을 것이라는 가설을 세웠다. 그리고 평소 운동을 꾸준히 하지 않는 고등학생 100명을 모집하여 50명씩 <word>(ㄹ) (A) 집단<word/>과 <word>(ㅁ) (B) 집단<word/>으로 나누었다. 갑은 <word>(ㅂ) 사전 검사<word/>를 실시한 후 6개월 동안 한 집단은 <word>(ㅅ) 매일 20분씩 달리기를 하도록 하였고<word/>, 다른 한 집단은 평소처럼 생활하도록 하였다. 6개월 후 사후 검사를 실시하여 사전 검사 결과와 비교해 보니 (A) 집단과 달리 (B) 집단의 경우 학업 성취도가 유의미하게 향상되어 갑은 가설이 타당하다는 결론을 내렸다.\n",
      "### 선택지: (A) (ㄱ)은 독립 변인, (ㄴ)은 종속 변인이다. (B) (ㄷ)에서 연구자의 가치 중립이 필수적이다. (C) (ㄹ)은 통제 집단, (ㅁ)은 실험 집단이다. (D) (ㅂ)은 실험 처치 전 독립 변인을 측정하기 위한 검사이다. (E) (ㅅ)은 종속 변인에 대한 조작적 정의를 바탕으로 한 실험 처치이다.\n",
      "=================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 5/11 [00:12<00:15,  2.53s/it, general_knowledge] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------date_understanding-------------------\n",
      "다음 질문에 대답으로 가장 적절한 것을 고르시요.\n",
      "### 질문:\n",
      "올해는 2020년, 오늘은 광복절 입니다. 친구와 익일 후에 만나기로 약속을 잡았다면, 우리가 만나는 날짜는 언제인가요?\n",
      "\n",
      "### 선택지:\n",
      "(A) 2020-08-17\n",
      "(B) 2020-08-13\n",
      "(C) 2020-08-16\n",
      "(D) 2022-08-16\n",
      "(E) 2028-11-19\n",
      "\n",
      "### 정답:\n",
      "=================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 6/11 [00:13<00:11,  2.24s/it, history]          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------general_knowledge-------------------\n",
      "다음 질문을 읽고 정답으로 가장 알맞은 것을 고르시요.\n",
      "    \n",
      "### 질문: \n",
      "다음은 무엇에 대한 이야기입니까?\n",
      "### 참고:한국에서는 명절에 조상의 산소를 찾아가 인사를 드리고 산소를 살핀다.\n",
      "\n",
      "### 선택지: \n",
      "(A) 추석\n",
      "(B) 제사\n",
      "(C) 성묘\n",
      "(D) 백일\n",
      "(E) 장례\n",
      "\n",
      "### 정답:\n",
      "=================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 7/11 [00:15<00:07,  1.99s/it, loan_words]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------history-------------------\n",
      "다음 질문을 읽고 정답으로 가장 알맞은 것을 고르시요.\n",
      "    \n",
      "### 질문: \n",
      "청동기 시대에 커다란 돌을 쌓아 만든 족장의 무덤을 무엇이라고 하는가?\n",
      "\n",
      "### 선택지: \n",
      "(A) 고분\n",
      "(B) 고인돌\n",
      "(C) 돌무덤\n",
      "(D) 돌기와집\n",
      "(E) 굴식돌방\n",
      "\n",
      "### 정답:\n",
      "=================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 8/11 [00:16<00:05,  1.78s/it, rare_words]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------loan_words-------------------\n",
      "다음 질문을 읽고 정답으로 가장 알맞은 것을 고르시요.\n",
      "    \n",
      "### 질문: \n",
      "언택트의 순화어 알맞은 것은?\n",
      "\n",
      "### 선택지: \n",
      "(A) 비전속\n",
      "(B) 부대기\n",
      "(C) 기대주\n",
      "(D) 상대방\n",
      "(E) 비대면\n",
      "\n",
      "### 정답:\n",
      "=================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 9/11 [00:17<00:03,  1.62s/it, standard_nomenclature]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------rare_words-------------------\n",
      "다음 질문을 읽고 정답으로 가장 알맞은 것을 고르시요.\n",
      "    \n",
      "### 질문: \n",
      "물건을 만들 때에 다듬지 않고 거칠게 대강 만드는 일의 의미를 가진 단어로 알맞은 것은?\n",
      "\n",
      "### 선택지: \n",
      "(A) 건널목\n",
      "(B) 나들목\n",
      "(C) 속재목\n",
      "(D) 건목\n",
      "(E) 조건문\n",
      "\n",
      "### 정답:\n",
      "=================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 10/11 [00:19<00:01,  1.51s/it, reading_comprehension]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------standard_nomenclature-------------------\n",
      "다음 질문을 읽고 정답으로 가장 알맞은 것을 고르시요.\n",
      "    \n",
      "### 질문: \n",
      "욜드의 올바른 표준 전문 용어로 알맞은 것은?\n",
      "\n",
      "### 선택지: \n",
      "(A) 청노년\n",
      "(B) 청소원\n",
      "(C) 청바지\n",
      "(D) 청동끌\n",
      "(E) 청소년복\n",
      "\n",
      "### 정답:\n",
      "=================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:20<00:00,  1.85s/it, reading_comprehension]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------reading_comprehension-------------------\n",
      "다음 지문을 읽고 질문에 대답으로 가장 적절한 것을 고르시요.\n",
      "\n",
      "### 지문: \n",
      "이제 한 편의 이야기를 들려 드립니다. 잘 듣고 물음에 답하십시오.\n",
      "자, 여러분! 안녕하십니까? 오늘은 제가 어제 꾼 꿈 이야기 하날 들려 드리겠습니다. 전 꿈속에서 낯선 거리를 걷고 있었습니다. 그러다가 홍미로운 간판을 발견했답니다. 행 복을 파는 가게. 그렇게 쓰여 있었습니다. 전 호기심으로 문을 열고 들어갔답니다. 그곳 에서는 한 노인이 물건을 팔고 있었습니다. 전 잠시 머뭇거리다가 노인에게 다가가서 물 었습니다. 여기서는 무슨 물건을 파느냐고요. 노인은 미소를 지으며, 원하는 것은 뭐든 다 살 수 있다고 말했습니다. 저는 제 귀를 의심했습니다. '무엇이든 다?' 전 무엇을 사야 할까 생각하다가 말했답니다. \"사랑, 부귀 그리고 지혜하고 건강도 사고 싶습니다. 저 자신뿐 아니라 우리 가족 모두 를 위해서요. 지금 바로 살 수 있나요?\" 그러자 노인은 빙긋이 웃으며 대답했습니다. \"젊은이, 한번 잘 보게나. 여기에서 팔고 있는 것은 무르익은 과일이 아니라 씨앗이라 네. 앞으로 좋은 열매를 맺으려면 이 씨앗들을 잘 가꾸어야 할 걸세.\"\n",
      "    \n",
      "### 질문:\n",
      " 이 이야기에서 얻을 수 있는 교훈으로 가장 적절한 것은?\n",
      "\n",
      "### 선택지:\n",
      "(A) 새로운 세계에 대한 열망을 가져야 한다.\n",
      "(B) 주어진 기회를 능동적으로 활용해야 한다.\n",
      "(C) 큰 것을 얻으려면 작은 것은 버려야 한다.\n",
      "(D) 물질적 가치보다 정신적 가치를 중시해야 한다.\n",
      "(E) 소망하는 바를 성취하기 위해서는 노력을 해야 한다.\n",
      "\n",
      "### 정답:\n",
      "=================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# check question format\n",
    "with  tqdm(total=len(mcqa)) as pbar:\n",
    "    for task in mcqa:\n",
    "        pbar.set_postfix_str(task)\n",
    "        ds = load_dataset(\"HAERAE-HUB/HAE_RAE_BENCH_1.1\", task)\n",
    "        df = ds['test'].to_pandas()\n",
    "        print(f\"-------------------{task}-------------------\")\n",
    "        print(df['query'].iloc[0])\n",
    "        print(\"=================================\")\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redefine the task\n",
    "import re\n",
    "from typing import List\n",
    "\n",
    "def parse_options(options_list_text: str)->List[str]:\n",
    "    try:\n",
    "        option_list = ast.literal_eval(options_list_text)\n",
    "    except:\n",
    "        option_list = options_list_text.split(\"|\")\n",
    "    return option_list\n",
    "\n",
    "def clean_answer(answers: str)->str:\n",
    "    return re.sub(r\"\\(|\\)\", \"\", answers)\n",
    "\n",
    "\n",
    "def process_mcqa_task(task) -> pd.DataFrame:\n",
    "    ds = load_dataset(\"HAERAE-HUB/HAE_RAE_BENCH_1.1\", task)\n",
    "    df = ds['test'].to_pandas()\n",
    "    \n",
    "    # Apply parse_options and expand into separate columns\n",
    "    options_df = df['options'].apply(lambda x: pd.Series(parse_options(x), index=[\"A\", \"B\", \"C\", \"D\", \"E\"]))\n",
    "    df = pd.concat([df, options_df], axis=1)\n",
    "\n",
    "    df['answer'] = df['answer'].apply(clean_answer)\n",
    "    df['question'] = df['query']\n",
    "    df['categories'] = \"mcqa\"\n",
    "    return df[['question', 'A', 'B', 'C', 'D', 'E', 'answer', 'categories']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:19<00:00,  1.75s/it, reading_comprehension]     \n"
     ]
    }
   ],
   "source": [
    "with tqdm(total=len(mcqa)) as pbar:\n",
    "    for task in mcqa:\n",
    "        pbar.set_postfix_str(task)\n",
    "        df = process_mcqa_task(task)\n",
    "        df.to_csv(f\"/home/joeyliang/BenchWeaver/evaluation_data/hae-rae-bench/data/test/{task}_test.csv\", index=False)\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:01<00:01,  1.74s/it, proverbs_denoising]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------lyrics_denoising-------------------\n",
      "다음은 제이티엘(JTL)의 노래 Without Your Love의 가사 중 일부분입니다. 주어진 단어를 활용해 [MASK]에 들어갈 가사를 생성하시요.\n",
      "\n",
      "### 가사: \n",
      "it's without without your love\n",
      "[MASK]'[MASK] [MASK] [MASK]'[MASK] [MASK] [MASK] [MASK]\n",
      "believe it you'd better believe it\n",
      "감정의 흐름을 잃어버려 공간 속에 난 갇혔어\n",
      "without your loving\n",
      "햇빛을 내려 비가 내리게 \n",
      "햇님을 담아 별님을 담아 나 상상했던 이상을 찾아 \n",
      "It's without without your love\n",
      "\n",
      "### 단어: ['love', 'without', \"It's\", 'your', \"it's\", 'without']\n",
      "\n",
      "## 정답:\n",
      "=================================\n",
      "nan\n",
      "=================================\n",
      "It's without it's without your love\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:03<00:00,  1.58s/it, proverbs_denoising]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------proverbs_denoising-------------------\n",
      "다음은 어떤 한국 속담에 대한 뜻풀이 입니다. 다음 뜻풀이를 읽고 주어진 단어를 사용해 해당 속담을 생성하시요.\n",
      "\n",
      "### 뜻풀이: \n",
      "일의 차례가 뒤바뀌었음을 비유적으로 이르는 말.\n",
      "\n",
      "### 단어: ['뒤에', '하고', '말', '앞에', '뒤에', '말', '할', '할', '앞에', '하고']\n",
      "\n",
      "## 정답:\n",
      "=================================\n",
      "nan\n",
      "=================================\n",
      "앞에 할 말 뒤에 하고 뒤에 할 말 앞에 하고\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with tqdm(total=len(opqa)) as pbar:\n",
    "    for task in opqa:\n",
    "        pbar.set_postfix_str(task)\n",
    "        ds = load_dataset(\"HAERAE-HUB/HAE_RAE_BENCH_1.1\", task)\n",
    "        df = ds['test'].to_pandas()\n",
    "        print(f\"-------------------{task}-------------------\")\n",
    "        print(df['query'].iloc[0])\n",
    "        print(\"=================================\")\n",
    "        print(df['options'].iloc[0])\n",
    "        print(\"=================================\")\n",
    "        print(df['answer'].iloc[0])\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_opqa_task(task) -> pd.DataFrame:\n",
    "    ds = load_dataset(\"HAERAE-HUB/HAE_RAE_BENCH_1.1\", task)\n",
    "    df = ds['test'].to_pandas()\n",
    "    df['A'] = \"\"\n",
    "    df['B'] = \"\"\n",
    "    df['C'] = \"\"\n",
    "    df['D'] = \"\"\n",
    "    df['E'] = \"\"\n",
    "    df['question'] = df['query']\n",
    "    df['categories'] = \"opqa\"\n",
    "    \n",
    "    return df[['question', 'A', 'B', 'C', 'D', 'E', 'answer', 'categories']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.36s/it, proverbs_denoising]\n"
     ]
    }
   ],
   "source": [
    "with tqdm(total=len(opqa)) as pbar:\n",
    "    for task in opqa:\n",
    "        pbar.set_postfix_str(task)\n",
    "        df = process_opqa_task(task)\n",
    "        df.to_csv(f\"/home/joeyliang/BenchWeaver/evaluation_data/hae-rae-bench/data/test/{task}_test.csv\", index=False)\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KMMLU (Hard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "supercategories = {\n",
    "        \"accounting\": \"HUMSS\",\n",
    "        \"agricultural_sciences\": \"Other\",\n",
    "        \"aviation_engineering_and_maintenance\": \"Applied Science\",\n",
    "        \"biology\": \"STEM\",\n",
    "        \"chemical_engineering\": \"STEM\",\n",
    "        \"chemistry\": \"STEM\",\n",
    "        \"civil_engineering\": \"STEM\",\n",
    "        \"computer_science\": \"STEM\",\n",
    "        \"construction\": \"Other\",\n",
    "        \"criminal_law\": \"HUMSS\",\n",
    "        \"ecology\": \"STEM\",\n",
    "        \"economics\": \"HUMSS\",\n",
    "        \"education\": \"HUMSS\",\n",
    "        \"electrical_engineering\": \"STEM\",\n",
    "        \"electronics_engineering\": \"Applied Science\",\n",
    "        \"energy_management\": \"Applied Science\",\n",
    "        \"environmental_science\": \"Applied Science\",\n",
    "        \"fashion\": \"Other\",\n",
    "        \"food_processing\": \"Other\",\n",
    "        \"gas_technology_and_engineering\": \"Applied Science\",\n",
    "        \"geomatics\": \"Applied Science\",\n",
    "        \"health\": \"Other\",\n",
    "        \"industrial_engineer\": \"Applied Science\",\n",
    "        \"information_technology\": \"STEM\",\n",
    "        \"interior_architecture_and_design\": \"Other\",\n",
    "        \"law\": \"HUMSS\",\n",
    "        \"machine_design_and_manufacturing\": \"Applied Science\",\n",
    "        \"management\": \"HUMSS\",\n",
    "        \"maritime_engineering\": \"Applied Science\",\n",
    "        \"marketing\": \"Other\",\n",
    "        \"materials_engineering\": \"STEM\",\n",
    "        \"mechanical_engineering\": \"STEM\",\n",
    "        \"nondestructive_testing\": \"Applied Science\",\n",
    "        \"patent\": \"Other\",\n",
    "        \"political_science_and_sociology\": \"HUMSS\",\n",
    "        \"psychology\": \"HUMSS\",\n",
    "        \"public_safety\": \"Other\",\n",
    "        \"railway_and_automotive_engineering\": \"Applied Science\",\n",
    "        \"real_estate\": \"Other\",\n",
    "        \"refrigerating_machinery\": \"Other\",\n",
    "        \"social_welfare\": \"HUMSS\",\n",
    "        \"taxation\": \"HUMSS\",\n",
    "        \"telecommunications_and_wireless_technology\": \"Applied Science\",\n",
    "        \"korean_history\": \"HUMSS\",\n",
    "        \"math\": \"STEM\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Applied Science', 'HUMSS', 'Other', 'STEM'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(supercategories.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "mapping = {}\n",
    "for k, v in supercategories.items():\n",
    "    mapping[k] = {\n",
    "        \"name\": k.replace(\"_\", \" \"),\n",
    "        \"category\": v\n",
    "    }\n",
    "    \n",
    "with open(\"/home/joeyliang/BenchWeaver/evaluation_data/kmmlu/mapping.json\", \"w\") as f:\n",
    "    json.dump(mapping, f, indent=2)\n",
    "    \n",
    "with open(\"/home/joeyliang/BenchWeaver/evaluation_data/kmmlu-hard/mapping.json\", \"w\") as f:\n",
    "    json.dump(mapping, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accounting',\n",
       " 'agricultural_sciences',\n",
       " 'aviation_engineering_and_maintenance',\n",
       " 'biology',\n",
       " 'chemical_engineering',\n",
       " 'chemistry',\n",
       " 'civil_engineering',\n",
       " 'computer_science',\n",
       " 'construction',\n",
       " 'criminal_law',\n",
       " 'ecology',\n",
       " 'economics',\n",
       " 'education',\n",
       " 'electrical_engineering',\n",
       " 'electronics_engineering',\n",
       " 'energy_management',\n",
       " 'environmental_science',\n",
       " 'fashion',\n",
       " 'food_processing',\n",
       " 'gas_technology_and_engineering',\n",
       " 'geomatics',\n",
       " 'health',\n",
       " 'industrial_engineer',\n",
       " 'information_technology',\n",
       " 'interior_architecture_and_design',\n",
       " 'law',\n",
       " 'machine_design_and_manufacturing',\n",
       " 'management',\n",
       " 'maritime_engineering',\n",
       " 'marketing',\n",
       " 'materials_engineering',\n",
       " 'mechanical_engineering',\n",
       " 'nondestructive_testing',\n",
       " 'patent',\n",
       " 'political_science_and_sociology',\n",
       " 'psychology',\n",
       " 'public_safety',\n",
       " 'railway_and_automotive_engineering',\n",
       " 'real_estate',\n",
       " 'refrigerating_machinery',\n",
       " 'social_welfare',\n",
       " 'taxation',\n",
       " 'telecommunications_and_wireless_technology',\n",
       " 'korean_history',\n",
       " 'math']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = ['Accounting', 'Agricultural-Sciences', 'Aviation-Engineering-and-Maintenance', 'Biology', 'Chemical-Engineering', 'Chemistry', 'Civil-Engineering', 'Computer-Science', 'Construction', 'Criminal-Law', 'Ecology', 'Economics', 'Education', 'Electrical-Engineering', 'Electronics-Engineering', 'Energy-Management', 'Environmental-Science', 'Fashion', 'Food-Processing', 'Gas-Technology-and-Engineering', 'Geomatics', 'Health', 'Industrial-Engineer', 'Information-Technology', 'Interior-Architecture-and-Design', 'Law', 'Machine-Design-and-Manufacturing', 'Management', 'Maritime-Engineering', 'Marketing', 'Materials-Engineering', 'Mechanical-Engineering', 'Nondestructive-Testing', 'Patent', 'Political-Science-and-Sociology', 'Psychology', 'Public-Safety', 'Railway-and-Automotive-Engineering', 'Real-Estate', 'Refrigerating-Machinery', 'Social-Welfare', 'Taxation', 'Telecommunications-and-Wireless-Technology', 'Korean-History', 'Math']\n",
    "\n",
    "task_list = [t.lower().replace(\"-\", \"_\") for t in task]\n",
    "task_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joeyliang/anaconda3/envs/BenchWeaver/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tqdm(total=len(task)) as pbar:\n",
    "    for t in task:\n",
    "        pbar.set_postfix_str(t)\n",
    "        ds = load_dataset(\"HAERAE-HUB/KMMLU\", t)\n",
    "        train_df = ds['train'].to_pandas()\n",
    "        test_df = ds['test'].to_pandas()\n",
    "        dev_df = ds['dev'].to_pandas()\n",
    "        task_name = t.lower().replace(\"-\", \"_\")\n",
    "        train_df.to_csv(f\"/home/joeyliang/BenchWeaver/evaluation_data/kmmlu/data/dev/{task_name}_dev.csv\", index=False)\n",
    "        dev_df.to_csv(f\"/home/joeyliang/BenchWeaver/evaluation_data/kmmlu/data/val/{task_name}_val.csv\", index=False)\n",
    "        test_df.to_csv(f\"/home/joeyliang/BenchWeaver/evaluation_data/kmmlu/data/test/{task_name}_test.csv\", index=False)\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [01:05<00:00,  1.45s/it, Math]                                      \n"
     ]
    }
   ],
   "source": [
    "        \n",
    "with tqdm(total=len(task)) as pbar:\n",
    "    for t in task:\n",
    "        pbar.set_postfix_str(t)\n",
    "        task_name = t.lower().replace(\"-\", \"_\")\n",
    "        ds = load_dataset(\"HAERAE-HUB/KMMLU-HARD\", task_name)\n",
    "        test_df = ds['test'].to_pandas()\n",
    "        dev_df = ds['dev'].to_pandas()\n",
    "        test_df.rename(columns={\"cot\": \"explanation\"}, inplace=True)\n",
    "        dev_df.rename(columns={\"cot\": \"explanation\"}, inplace=True)\n",
    "        dev_df.to_csv(f\"/home/joeyliang/BenchWeaver/evaluation_data/kmmlu-hard/data/dev/{task_name}_dev.csv\", index=False)\n",
    "        test_df.to_csv(f\"/home/joeyliang/BenchWeaver/evaluation_data/kmmlu-hard/data/test/{task_name}_test.csv\", index=False)\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TMMLU+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joeyliang/anaconda3/envs/BenchWeaver/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "task_list = [\n",
    "             'engineering_math', 'dentistry', 'traditional_chinese_medicine_clinical_medicine', 'clinical_psychology', 'technical', 'culinary_skills', 'mechanical', 'logic_reasoning', 'real_estate',\n",
    "             'general_principles_of_law', 'finance_banking', 'anti_money_laundering', 'ttqav2', 'marketing_management', 'business_management', 'organic_chemistry', 'advance_chemistry',\n",
    "             'physics', 'secondary_physics', 'human_behavior', 'national_protection', 'jce_humanities', 'politic_science', 'agriculture', 'official_document_management',\n",
    "             'financial_analysis', 'pharmacy', 'educational_psychology', 'statistics_and_machine_learning', 'management_accounting', 'introduction_to_law', 'computer_science', 'veterinary_pathology',\n",
    "             'accounting', 'fire_science', 'optometry', 'insurance_studies', 'pharmacology', 'taxation', 'trust_practice', 'geography_of_taiwan', 'physical_education', 'auditing', 'administrative_law',\n",
    "             'education_(profession_level)', 'economics', 'veterinary_pharmacology', 'nautical_science', 'occupational_therapy_for_psychological_disorders',\n",
    "             'basic_medical_science', 'macroeconomics', 'trade', 'chinese_language_and_literature', 'tve_design', 'junior_science_exam', 'junior_math_exam', 'junior_chinese_exam',\n",
    "             'junior_social_studies', 'tve_mathematics', 'tve_chinese_language', 'tve_natural_sciences', 'junior_chemistry', 'music', 'education', 'three_principles_of_people',\n",
    "             'taiwanese_hokkien'\n",
    "            ]\n",
    "\n",
    "base_dir = \"/home/joeyliang/BenchWeaver/evaluation_data/tmmluplus/data\"\n",
    "for task in task_list:\n",
    "    val = load_dataset('ikala/tmmluplus', task)['validation']\n",
    "    dev = load_dataset('ikala/tmmluplus', task)['train']\n",
    "    test = load_dataset('ikala/tmmluplus', task)['test']\n",
    "    # Convert datasets to DataFrames\n",
    "    val_df = val.to_pandas()\n",
    "    dev_df = dev.to_pandas()\n",
    "    test_df = test.to_pandas()\n",
    "    # Define file paths\n",
    "    val_file = os.path.join(base_dir, 'val', f\"{task}_val.csv\")\n",
    "    dev_file = os.path.join(base_dir, 'dev', f\"{task}_dev.csv\")\n",
    "    test_file = os.path.join(base_dir, 'test', f\"{task}_test.csv\")\n",
    "    # Create directories if they don't exist\n",
    "    os.makedirs(os.path.dirname(val_file), exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(dev_file), exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(test_file), exist_ok=True)\n",
    "    # Save DataFrames to CSV files\n",
    "    val_df.to_csv(val_file, index=False)\n",
    "    dev_df.to_csv(dev_file, index=False)\n",
    "    test_df.to_csv(test_file, index=False)\n",
    "\n",
    "# Define the zip file name\n",
    "zip_file = \"tmmluplus.zip\"\n",
    "\n",
    "# Function to zip a directory and its contents\n",
    "def zip_dir(directory, zip_file):\n",
    "    with zipfile.ZipFile(zip_file, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        for root, _, files in os.walk(directory):\n",
    "            for file in files:\n",
    "                zipf.write(os.path.join(root, file), os.path.relpath(os.path.join(root, file), directory))\n",
    "\n",
    "# Zip the directory\n",
    "zip_dir(base_dir, zip_file)\n",
    "# Remove the base directory after zipping\n",
    "shutil.rmtree(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dentistry</td>\n",
       "      <td>牙醫學</td>\n",
       "      <td>health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>traditional_chinese_medicine_clinical_medicine</td>\n",
       "      <td>中醫臨床醫學</td>\n",
       "      <td>health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>clinical_psychology</td>\n",
       "      <td>臨床心理學</td>\n",
       "      <td>psychology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>technical</td>\n",
       "      <td>技術工相關</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>culinary_skills</td>\n",
       "      <td>餐旅</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>music</td>\n",
       "      <td>音樂科</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>education</td>\n",
       "      <td>教育常識</td>\n",
       "      <td>education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>three_principles_of_people</td>\n",
       "      <td>三民主義</td>\n",
       "      <td>culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>taiwanese_hokkien</td>\n",
       "      <td>閩南語</td>\n",
       "      <td>culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>engineering_math</td>\n",
       "      <td>工程數學</td>\n",
       "      <td>math</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           subject    name    category\n",
       "0                                        dentistry     牙醫學      health\n",
       "1   traditional_chinese_medicine_clinical_medicine  中醫臨床醫學      health\n",
       "2                              clinical_psychology   臨床心理學  psychology\n",
       "3                                        technical   技術工相關       other\n",
       "4                                  culinary_skills      餐旅       other\n",
       "..                                             ...     ...         ...\n",
       "62                                           music     音樂科       other\n",
       "63                                       education    教育常識   education\n",
       "64                      three_principles_of_people    三民主義     culture\n",
       "65                               taiwanese_hokkien     閩南語     culture\n",
       "66                                engineering_math    工程數學        math\n",
       "\n",
       "[67 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/home/joeyliang/BenchWeaver/evaluation_data/tmmluplus/subject.tsv\", delimiter=\"\\t\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmlu_mapping = {\n",
    "    \"health\": \"Other\",\n",
    "    \"psychology\": \"Social Sciences\",\n",
    "    \"other\": \"Other\",\n",
    "    \"law\": \"Social Sciences\",\n",
    "    \"business\": \"Other\",\n",
    "    \"culture\": \"Humanities\",\n",
    "    \"chemistry\": \"STEM\",\n",
    "    \"physics\": \"STEM\",\n",
    "    \"politics\": \"Social Sciences\",\n",
    "    \"philosophy\": \"Humanities\",\n",
    "    \"math\": \"STEM\",\n",
    "    \"biology\": \"STEM\",\n",
    "    \"engineering\": \"STEM\",\n",
    "    \"computer science\": \"STEM\",\n",
    "    \"education\": \"Social Sciences\",\n",
    "    \"economics\": \"Social Sciences\",\n",
    "    \"geography\": \"Social Sciences\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "catogories = {}\n",
    "for idx in range(df.shape[0]):\n",
    "    catogories[df['subject'][idx]] = {\n",
    "        \"name\": df['name'][idx],\n",
    "        \"category\": mmlu_mapping[df['category'][idx]]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"/home/joeyliang/BenchWeaver/evaluation_data/tmmluplus/mapping.json\", \"w\") as f:\n",
    "    json.dump(catogories, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TMLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping ={\n",
    "    \"AST_civics\": {\"name\": \"分科測驗公民\", \"category\": \"Social Science\"},\n",
    "    \"AST_geography\": {\"name\": \"分科測驗地理\", \"category\": \"Social Science\"},\n",
    "    \"CAP_civics\": {\"name\": \"會考公民\", \"category\": \"Social Science\"},\n",
    "    \"CAP_geography\": {\"name\": \"會考地理\", \"category\": \"Social Science\"},\n",
    "    \"GSAT_civics\": {\"name\": \"學測公民\", \"category\": \"Social Science\"},\n",
    "    \"GSAT_geography\": {\"name\": \"學測地理\", \"category\": \"Social Science\"},\n",
    "    \"accountant\": {\"name\": \"會計師\", \"category\": \"Social Science\"},\n",
    "    \"clinical_psychologist\": {\"name\": \"臨床心理師\", \"category\": \"Social Science\"},\n",
    "    \"AST_biology\": {\"name\": \"分科測驗生物\", \"category\": \"STEM\"},\n",
    "    \"AST_chemistry\": {\"name\": \"分科測驗化學\", \"category\": \"STEM\"},\n",
    "    \"AST_mathematics\": {\"name\": \"分科測驗數學\", \"category\": \"STEM\"},\n",
    "    \"AST_physics\": {\"name\": \"分科測驗物理\", \"category\": \"STEM\"},\n",
    "    \"CAP_biology\": {\"name\": \"會考生物\", \"category\": \"STEM\"},\n",
    "    \"CAP_chemistry\": {\"name\": \"會考化學\", \"category\": \"STEM\"},\n",
    "    \"CAP_earth_science\": {\"name\": \"會考地球科學\", \"category\": \"STEM\"},\n",
    "    \"CAP_mathematics\": {\"name\": \"會考數學\", \"category\": \"STEM\"},\n",
    "    \"CAP_physics\": {\"name\": \"會考物理\", \"category\": \"STEM\"},\n",
    "    \"GSAT_biology\": {\"name\": \"學測生物\", \"category\": \"STEM\"},\n",
    "    \"GSAT_chemistry\": {\"name\": \"學測化學\", \"category\": \"STEM\"},\n",
    "    \"GSAT_earth_science\": {\"name\": \"學測地球科學\", \"category\": \"STEM\"},\n",
    "    \"GSAT_mathematics\": {\"name\": \"學測數學\", \"category\": \"STEM\"},\n",
    "    \"GSAT_physics\": {\"name\": \"學測物理\", \"category\": \"STEM\"},\n",
    "    \"AST_chinese\": {\"name\": \"分科測驗國文\", \"category\": \"Humanities\"},\n",
    "    \"AST_history\": {\"name\": \"分科測驗歷史\", \"category\": \"Humanities\"},\n",
    "    \"CAP_chinese\": {\"name\": \"會考國文\", \"category\": \"Humanities\"},\n",
    "    \"CAP_history\": {\"name\": \"會考歷史\", \"category\": \"Humanities\"},\n",
    "    \"GSAT_chinese\": {\"name\": \"學測國文\", \"category\": \"Humanities\"},\n",
    "    \"GSAT_history\": {\"name\": \"學測歷史\", \"category\": \"Humanities\"},\n",
    "    \"tour_guide\": {\"name\": \"導遊\", \"category\": \"Humanities\"},\n",
    "    \"tour_leader\": {\"name\": \"領隊\", \"category\": \"Humanities\"},\n",
    "    \"lawyer_qualification\": {\"name\": \"律師資格\", \"category\": \"Humanities\"},\n",
    "    \"driving_rule\": {\"name\": \"台灣駕駛規則\", \"category\": \"Taiwan Specific\"},\n",
    "    \"teacher_qualification\": {\"name\": \"教師資格\", \"category\": \"Taiwan Specific\"},\n",
    "    \"taiwan_tourist_resources\": {\"name\": \"台灣觀光資源\", \"category\": \"Taiwan Specific\"},\n",
    "    \"basic_traditional_chinese_medicine\": {\"name\": \"中醫基礎醫學\", \"category\": \"Others\"},\n",
    "    \"clinical_traditional_chinese_medicine\": {\"name\": \"中醫針灸\", \"category\": \"Others\"},\n",
    "    \"nutritionist\": {\"name\": \"營養師\", \"category\": \"Others\"}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AST_civics',\n",
       " 'AST_geography',\n",
       " 'CAP_civics',\n",
       " 'CAP_geography',\n",
       " 'GSAT_civics',\n",
       " 'GSAT_geography',\n",
       " 'accountant',\n",
       " 'clinical_psychologist',\n",
       " 'AST_biology',\n",
       " 'AST_chemistry',\n",
       " 'AST_mathematics',\n",
       " 'AST_physics',\n",
       " 'CAP_biology',\n",
       " 'CAP_chemistry',\n",
       " 'CAP_earth_science',\n",
       " 'CAP_mathematics',\n",
       " 'CAP_physics',\n",
       " 'GSAT_biology',\n",
       " 'GSAT_chemistry',\n",
       " 'GSAT_earth_science',\n",
       " 'GSAT_mathematics',\n",
       " 'GSAT_physics',\n",
       " 'AST_chinese',\n",
       " 'AST_history',\n",
       " 'CAP_chinese',\n",
       " 'CAP_history',\n",
       " 'GSAT_chinese',\n",
       " 'GSAT_history',\n",
       " 'tour_guide',\n",
       " 'tour_leader',\n",
       " 'lawyer_qualification',\n",
       " 'driving_rule',\n",
       " 'teacher_qualification',\n",
       " 'taiwan_tourist_resources',\n",
       " 'basic_traditional_chinese_medicine',\n",
       " 'clinical_traditional_chinese_medicine',\n",
       " 'nutritionist']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_list = list(mapping.keys())\n",
    "task_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"/home/joeyliang/BenchWeaver/evaluation_data/tmlu/mapping.json\", \"w\") as f:\n",
    "    json.dump(mapping, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37/37 [01:17<00:00,  2.08s/it]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "def process_df(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    choice_lists = []\n",
    "    for idx in range(df.shape[0]):\n",
    "        answer_opt = df['answer'].iloc[idx]\n",
    "        choice_list = [\n",
    "            df.loc[idx, 'A'],\n",
    "            df.loc[idx, 'B'],\n",
    "            df.loc[idx, 'C'],\n",
    "            df.loc[idx, 'D'],\n",
    "            df.loc[idx, 'E'],\n",
    "            df.loc[idx, 'F'],\n",
    "        ]\n",
    "        df.loc[idx, 'choices'] = str(choice_list)\n",
    "        df.loc[idx, 'answer'] = df.loc[idx, answer_opt]\n",
    "    df = df[['question', 'choices', 'answer']]\n",
    "    return df\n",
    "\n",
    "base_dir = \"/home/joeyliang/BenchWeaver/evaluation_data/tmlu/data\"\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "for task in tqdm(mapping.keys()):\n",
    "    ds = load_dataset(\"miulab/tmlu\", task)\n",
    "    dev_df = process_df(ds['dev'].to_pandas())\n",
    "    test_df = process_df(ds['test'].to_pandas())\n",
    "    dev_file = os.path.join(base_dir, 'dev', f\"{task}_dev.csv\")\n",
    "    test_file = os.path.join(base_dir, 'test', f\"{task}_test.csv\")\n",
    "    os.makedirs(os.path.dirname(dev_file), exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(test_file), exist_ok=True)\n",
    "    dev_df.to_csv(dev_file, index=False)\n",
    "    test_df.to_csv(test_file, index=False)\n",
    "\n",
    "# Define the zip file name\n",
    "zip_file = \"/home/joeyliang/BenchWeaver/evaluation_data/tmlu/tmlu.zip\"\n",
    "\n",
    "# Function to zip a directory and its contents\n",
    "def zip_dir(directory, zip_file):\n",
    "    with zipfile.ZipFile(zip_file, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        for root, _, files in os.walk(directory):\n",
    "            for file in files:\n",
    "                zipf.write(os.path.join(root, file), os.path.relpath(os.path.join(root, file), directory))\n",
    "\n",
    "# Zip the directory\n",
    "zip_dir(base_dir, zip_file)\n",
    "# Remove the base directory after zipping\n",
    "shutil.rmtree(base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DRCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Any\n",
    "def load_json(file_path:str) -> Any:\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "train_data = load_json(\"/home/joeyliang/BenchWeaver/evaluation_data/drcd/DRCD_training.json\")\n",
    "dev_data = load_json(\"/home/joeyliang/BenchWeaver/evaluation_data/drcd/DRCD_dev.json\")\n",
    "test_data = load_json(\"/home/joeyliang/BenchWeaver/evaluation_data/drcd/DRCD_test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_record = {\n",
    "    \"title\": [],\n",
    "    \"id\": [],\n",
    "    \"context\": [],\n",
    "    \"question\": [],\n",
    "    \"answer\": [],\n",
    "    \"answer_start\": [],\n",
    "}\n",
    "dev_record = {\n",
    "    \"title\": [],\n",
    "    \"id\": [],\n",
    "    \"context\": [],\n",
    "    \"question\": [],\n",
    "    \"answer\": [],\n",
    "    \"answer_start\": [],\n",
    "}\n",
    "test_record = {\n",
    "    \"title\": [],\n",
    "    \"id\": [],\n",
    "    \"context\": [],\n",
    "    \"question\": [],\n",
    "    \"answer\": [],\n",
    "    \"answer_start\": [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joeyliang/anaconda3/envs/BenchWeaver/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "100%|██████████| 1960/1960 [00:00<00:00, 115814.15it/s]\n",
      "100%|██████████| 383/383 [00:00<00:00, 161953.67it/s]\n",
      "100%|██████████| 378/378 [00:00<00:00, 165116.32it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "for idx in tqdm(range(len(train_data['data']))):\n",
    "    for paragraph in train_data['data'][idx]['paragraphs']:\n",
    "        for qa in paragraph['qas']:\n",
    "            train_record['title'].append(train_data['data'][idx]['title'])\n",
    "            train_record['id'].append(qa['id'])\n",
    "            train_record['context'].append(paragraph['context'])\n",
    "            train_record['question'].append(qa['question'])\n",
    "            train_record['answer'].append(qa['answers'][0]['text'])\n",
    "            train_record['answer_start'].append(qa['answers'][0]['answer_start'])\n",
    "\n",
    "for idx in tqdm(range(len(dev_data['data']))):\n",
    "    for paragraph in dev_data['data'][idx]['paragraphs']:\n",
    "        for qa in paragraph['qas']:\n",
    "            dev_record['title'].append(dev_data['data'][idx]['title'])\n",
    "            dev_record['id'].append(qa['id'])\n",
    "            dev_record['context'].append(paragraph['context'])\n",
    "            dev_record['question'].append(qa['question'])\n",
    "            dev_record['answer'].append(qa['answers'][0]['text'])\n",
    "            dev_record['answer_start'].append(qa['answers'][0]['answer_start'])\n",
    "            \n",
    "for idx in tqdm(range(len(test_data['data']))):\n",
    "    for paragraph in test_data['data'][idx]['paragraphs']:\n",
    "        for qa in paragraph['qas']:\n",
    "            test_record['title'].append(test_data['data'][idx]['title'])\n",
    "            test_record['id'].append(qa['id'])\n",
    "            test_record['context'].append(paragraph['context'])\n",
    "            test_record['question'].append(qa['question'])\n",
    "            test_record['answer'].append(qa['answers'][0]['text'])\n",
    "            test_record['answer_start'].append(qa['answers'][0]['answer_start'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>id</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>梵文</td>\n",
       "      <td>1147-2-1</td>\n",
       "      <td>要探討從梨俱吠陀到波你尼時代梵語的發展，可以考察印度教其它文本，如娑摩吠陀、夜柔吠陀、阿闥婆...</td>\n",
       "      <td>夜柔吠陀與阿闥婆吠陀均可以最為研究哪一門語言的參考？</td>\n",
       "      <td>梵語</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>梵文</td>\n",
       "      <td>1147-2-2</td>\n",
       "      <td>要探討從梨俱吠陀到波你尼時代梵語的發展，可以考察印度教其它文本，如娑摩吠陀、夜柔吠陀、阿闥婆...</td>\n",
       "      <td>哪一本書規範了梵語的正確語法？</td>\n",
       "      <td>八篇書</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>梵文</td>\n",
       "      <td>1147-2-3</td>\n",
       "      <td>要探討從梨俱吠陀到波你尼時代梵語的發展，可以考察印度教其它文本，如娑摩吠陀、夜柔吠陀、阿闥婆...</td>\n",
       "      <td>中古印度-雅利安語方言的前身與哪一門語言都同時在古印度使用？</td>\n",
       "      <td>梵語</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>梵文</td>\n",
       "      <td>1147-3-1</td>\n",
       "      <td>波你尼所定義的梵語是從更早的「吠陀」形式演化出來的。學者經常把吠陀梵語和古典或「波你尼」梵語...</td>\n",
       "      <td>波你尼梵語與哪一門語言非常相似？</td>\n",
       "      <td>吠陀梵語</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>梵文</td>\n",
       "      <td>1147-3-2</td>\n",
       "      <td>波你尼所定義的梵語是從更早的「吠陀」形式演化出來的。學者經常把吠陀梵語和古典或「波你尼」梵語...</td>\n",
       "      <td>印度教的最早宗教文本以什麼語言撰寫？</td>\n",
       "      <td>吠陀梵語</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3488</th>\n",
       "      <td>喀喇汗国</td>\n",
       "      <td>6516-5-2</td>\n",
       "      <td>著名的薩圖克·博格拉汗是這個國家第一個皈依伊斯蘭教的可汗，更重要的是他也是世界歷史上第一個皈...</td>\n",
       "      <td>突厥人的第一個伊斯蘭教王朝是?</td>\n",
       "      <td>喀喇汗國</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3489</th>\n",
       "      <td>喀喇汗国</td>\n",
       "      <td>6516-5-3</td>\n",
       "      <td>著名的薩圖克·博格拉汗是這個國家第一個皈依伊斯蘭教的可汗，更重要的是他也是世界歷史上第一個皈...</td>\n",
       "      <td>哪一個地區的穆斯林商人讓薩圖克對伊斯蘭文化十分嚮往?</td>\n",
       "      <td>阿圖什</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3490</th>\n",
       "      <td>納瓦拉</td>\n",
       "      <td>6519-1-1</td>\n",
       "      <td>納瓦拉，正式名稱是納瓦拉特許共同體，是西班牙北部一個自治區，全區僅有納瓦拉一省，面積10,3...</td>\n",
       "      <td>哪一個城市是納瓦拉的首府?</td>\n",
       "      <td>潘普洛納</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3491</th>\n",
       "      <td>納瓦拉</td>\n",
       "      <td>6519-1-2</td>\n",
       "      <td>納瓦拉，正式名稱是納瓦拉特許共同體，是西班牙北部一個自治區，全區僅有納瓦拉一省，面積10,3...</td>\n",
       "      <td>上納瓦拉在哪一年被西班牙兼併?</td>\n",
       "      <td>1512年</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492</th>\n",
       "      <td>納瓦拉</td>\n",
       "      <td>6519-1-3</td>\n",
       "      <td>納瓦拉，正式名稱是納瓦拉特許共同體，是西班牙北部一個自治區，全區僅有納瓦拉一省，面積10,3...</td>\n",
       "      <td>西班牙波旁王朝的建立者是誰?</td>\n",
       "      <td>菲利浦五世</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3493 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     title        id                                            context  \\\n",
       "0       梵文  1147-2-1  要探討從梨俱吠陀到波你尼時代梵語的發展，可以考察印度教其它文本，如娑摩吠陀、夜柔吠陀、阿闥婆...   \n",
       "1       梵文  1147-2-2  要探討從梨俱吠陀到波你尼時代梵語的發展，可以考察印度教其它文本，如娑摩吠陀、夜柔吠陀、阿闥婆...   \n",
       "2       梵文  1147-2-3  要探討從梨俱吠陀到波你尼時代梵語的發展，可以考察印度教其它文本，如娑摩吠陀、夜柔吠陀、阿闥婆...   \n",
       "3       梵文  1147-3-1  波你尼所定義的梵語是從更早的「吠陀」形式演化出來的。學者經常把吠陀梵語和古典或「波你尼」梵語...   \n",
       "4       梵文  1147-3-2  波你尼所定義的梵語是從更早的「吠陀」形式演化出來的。學者經常把吠陀梵語和古典或「波你尼」梵語...   \n",
       "...    ...       ...                                                ...   \n",
       "3488  喀喇汗国  6516-5-2  著名的薩圖克·博格拉汗是這個國家第一個皈依伊斯蘭教的可汗，更重要的是他也是世界歷史上第一個皈...   \n",
       "3489  喀喇汗国  6516-5-3  著名的薩圖克·博格拉汗是這個國家第一個皈依伊斯蘭教的可汗，更重要的是他也是世界歷史上第一個皈...   \n",
       "3490   納瓦拉  6519-1-1  納瓦拉，正式名稱是納瓦拉特許共同體，是西班牙北部一個自治區，全區僅有納瓦拉一省，面積10,3...   \n",
       "3491   納瓦拉  6519-1-2  納瓦拉，正式名稱是納瓦拉特許共同體，是西班牙北部一個自治區，全區僅有納瓦拉一省，面積10,3...   \n",
       "3492   納瓦拉  6519-1-3  納瓦拉，正式名稱是納瓦拉特許共同體，是西班牙北部一個自治區，全區僅有納瓦拉一省，面積10,3...   \n",
       "\n",
       "                            question answer  answer_start  \n",
       "0         夜柔吠陀與阿闥婆吠陀均可以最為研究哪一門語言的參考？     梵語            14  \n",
       "1                    哪一本書規範了梵語的正確語法？    八篇書           133  \n",
       "2     中古印度-雅利安語方言的前身與哪一門語言都同時在古印度使用？     梵語           315  \n",
       "3                   波你尼梵語與哪一門語言非常相似？   吠陀梵語            31  \n",
       "4                 印度教的最早宗教文本以什麼語言撰寫？   吠陀梵語            96  \n",
       "...                              ...    ...           ...  \n",
       "3488                 突厥人的第一個伊斯蘭教王朝是?   喀喇汗國            58  \n",
       "3489      哪一個地區的穆斯林商人讓薩圖克對伊斯蘭文化十分嚮往?    阿圖什           181  \n",
       "3490                   哪一個城市是納瓦拉的首府?   潘普洛納            62  \n",
       "3491                 上納瓦拉在哪一年被西班牙兼併?  1512年           214  \n",
       "3492                  西班牙波旁王朝的建立者是誰?  菲利浦五世           300  \n",
       "\n",
       "[3493 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.DataFrame(train_record)\n",
    "dev_df = pd.DataFrame(dev_record)\n",
    "test_df = pd.DataFrame(test_record)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"/home/joeyliang/BenchWeaver/evaluation_data/drcd/data/dev/all_dev.csv\", index=False)\n",
    "dev_df.to_csv(\"/home/joeyliang/BenchWeaver/evaluation_data/drcd/data/val/all_val.csv\", index=False)\n",
    "test_df.to_csv(\"/home/joeyliang/BenchWeaver/evaluation_data/drcd/data/test/all_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "123"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BenchWeaver",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
