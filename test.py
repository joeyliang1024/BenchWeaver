
import collections
import json
import math
import re
from tqdm import tqdm
from multiprocessing import Pool, cpu_count

class CodeCorruptionDetector:
    """æª¢æ¸¬ç¨‹å¼ç¢¼æ˜¯å¦å› é‡è¤‡å…§å®¹è€Œæå£çš„é¡åˆ¥"""
    
    def __init__(self):
        # å¯èª¿æ•´çš„é–¾å€¼åƒæ•¸
        self.max_consecutive_repeat = 50  # é€£çºŒé‡è¤‡å­—å…ƒçš„æœ€å¤§æ•¸é‡
        self.entropy_threshold = 2.5      # ç†µçš„æœ€å°é–¾å€¼
        self.repetitive_pattern_threshold = 0.7  # é‡è¤‡æ¨¡å¼æ¯”ä¾‹é–¾å€¼
        self.min_code_length = 50         # æœ€å°ç¨‹å¼ç¢¼é•·åº¦æ‰é€²è¡Œæª¢æ¸¬
    
    def detect_corruption(self, code_string: str, passed: bool, verbose: bool = True) -> dict:
        """
        æª¢æ¸¬ç¨‹å¼ç¢¼æ˜¯å¦æå£
        
        Args:
            code_string: å¾…æª¢æŸ¥çš„ç¨‹å¼ç¢¼å­—ä¸²
            verbose: æ˜¯å¦è¼¸å‡ºè©³ç´°ä¿¡æ¯
            
        Returns:
            dict: åŒ…å«æª¢æ¸¬çµæœçš„å­—å…¸
        """
        result = {
            'is_corrupted': False,
            'corruption_reasons': [],
            'details': {},
            'confidence': 0.0
        }
        # å¦‚æœç¨‹å¼ç¢¼å·²ç¶“é€šéæª¢æ¸¬ï¼Œå‰‡ä¸é€²è¡Œæå£æª¢æ¸¬
        if passed:
            result['is_corrupted'] = False
            result['confidence'] = 0.0
            if verbose:
                print("ç¨‹å¼ç¢¼å·²é€šéæª¢æ¸¬ï¼Œç„¡éœ€é€²è¡Œæå£æª¢æ¸¬ã€‚")
            return result
        
        if len(code_string) < self.min_code_length:
            result['details']['length'] = len(code_string)
            if verbose:
                print(f"ç¨‹å¼ç¢¼é•·åº¦å¤ªçŸ­ ({len(code_string)} å­—å…ƒ)ï¼Œè·³éæª¢æ¸¬ã€‚")
            return result
        
        corruption_indicators = 0
        max_indicators = 4
        
        # 1. æª¢æŸ¥é€£çºŒé‡è¤‡å­—å…ƒ
        consecutive_repeat = self._check_consecutive_repeats(code_string)
        result['details']['max_consecutive_repeats'] = consecutive_repeat
        
        if consecutive_repeat >= self.max_consecutive_repeat:
            result['corruption_reasons'].append(f"æª¢æ¸¬åˆ° {consecutive_repeat} å€‹é€£çºŒé‡è¤‡å­—å…ƒ")
            corruption_indicators += 1
            if verbose:
                print(f"âš ï¸  ç™¼ç¾ {consecutive_repeat} å€‹é€£çºŒé‡è¤‡å­—å…ƒ")
        
        # 2. æª¢æŸ¥ç†µå€¼
        entropy = self._calculate_entropy(code_string)
        result['details']['entropy'] = entropy
        
        if entropy < self.entropy_threshold:
            result['corruption_reasons'].append(f"ç†µå€¼éä½ ({entropy:.2f} < {self.entropy_threshold})")
            corruption_indicators += 1
            if verbose:
                print(f"âš ï¸  ç†µå€¼éä½: {entropy:.2f}")
        
        # 3. æª¢æŸ¥é‡è¤‡æ¨¡å¼
        repetitive_ratio = self._check_repetitive_patterns(code_string)
        result['details']['repetitive_pattern_ratio'] = repetitive_ratio
        
        if repetitive_ratio > self.repetitive_pattern_threshold:
            result['corruption_reasons'].append(f"é‡è¤‡æ¨¡å¼æ¯”ä¾‹éé«˜ ({repetitive_ratio:.2f})")
            corruption_indicators += 1
            if verbose:
                print(f"âš ï¸  é‡è¤‡æ¨¡å¼æ¯”ä¾‹éé«˜: {repetitive_ratio:.2f}")
        
        # 4. æª¢æŸ¥ç•°å¸¸å­—ç¬¦åˆ†ä½ˆ
        char_anomaly = self._check_character_anomalies(code_string)
        result['details']['character_anomaly_score'] = char_anomaly
        
        if char_anomaly > 0.8:
            result['corruption_reasons'].append(f"å­—ç¬¦åˆ†ä½ˆç•°å¸¸ (åˆ†æ•¸: {char_anomaly:.2f})")
            corruption_indicators += 1
            if verbose:
                print(f"âš ï¸  å­—ç¬¦åˆ†ä½ˆç•°å¸¸ï¼Œåˆ†æ•¸: {char_anomaly:.2f}")
        
        # è¨ˆç®—æ•´é«”ä¿¡å¿ƒåº¦å’Œçµæœ
        result['confidence'] = corruption_indicators / max_indicators
        result['is_corrupted'] = corruption_indicators >= 2  # è‡³å°‘å…©å€‹æŒ‡æ¨™ç•°å¸¸æ‰åˆ¤æ–·ç‚ºæå£
        
        if verbose:
            print(f"\nğŸ“Š æª¢æ¸¬çµæœ:")
            print(f"   æå£å¯èƒ½æ€§: {'é«˜' if result['is_corrupted'] else 'ä½'}")
            print(f"   ä¿¡å¿ƒåº¦: {result['confidence']:.2f}")
            print(f"   ç•°å¸¸æŒ‡æ¨™æ•¸: {corruption_indicators}/{max_indicators}")
        
        return result
    
    def _check_consecutive_repeats(self, code_string: str) -> int:
        """æª¢æŸ¥æœ€å¤§é€£çºŒé‡è¤‡å­—å…ƒæ•¸"""
        if len(code_string) <= 1:
            return 0
        
        max_repeat = 0
        current_repeat = 0
        
        for i in range(1, len(code_string)):
            if code_string[i] == code_string[i-1]:
                current_repeat += 1
                max_repeat = max(max_repeat, current_repeat)
            else:
                current_repeat = 0
        
        return max_repeat
    
    def _calculate_entropy(self, code_string: str) -> float:
        """è¨ˆç®—å­—ä¸²çš„ç†µå€¼"""
        if not code_string:
            return 0.0
        
        frequencies = collections.Counter(code_string)
        total_chars = len(code_string)
        
        entropy = 0.0
        for freq in frequencies.values():
            probability = freq / total_chars
            entropy -= probability * math.log2(probability)
        
        return entropy
    
    def _check_repetitive_patterns(self, code_string: str) -> float:
        """æª¢æŸ¥é‡è¤‡æ¨¡å¼çš„æ¯”ä¾‹"""
        # ç§»é™¤ç©ºç™½å­—ç¬¦é€²è¡Œåˆ†æ
        cleaned_code = re.sub(r'\s+', '', code_string)
        if len(cleaned_code) < 20:
            return 0.0
        
        # æŸ¥æ‰¾é‡è¤‡çš„å­å­—ä¸²
        repetitive_chars = 0
        
        # æª¢æŸ¥é•·åº¦ç‚º2-10çš„é‡è¤‡æ¨¡å¼
        for pattern_length in range(2, min(11, len(cleaned_code) // 4)):
            for i in range(len(cleaned_code) - pattern_length * 2):
                pattern = cleaned_code[i:i + pattern_length]
                # è¨ˆç®—æ­¤æ¨¡å¼åœ¨å¾ŒçºŒæ–‡æœ¬ä¸­çš„é‡è¤‡æ¬¡æ•¸
                remaining_text = cleaned_code[i + pattern_length:]
                repeats = 0
                pos = 0
                
                while pos <= len(remaining_text) - pattern_length:
                    if remaining_text[pos:pos + pattern_length] == pattern:
                        repeats += 1
                        pos += pattern_length
                    else:
                        pos += 1
                
                if repeats >= 3:  # è‡³å°‘é‡è¤‡3æ¬¡æ‰ç®—ç•°å¸¸
                    repetitive_chars += pattern_length * (repeats + 1)
        
        return min(1.0, repetitive_chars / len(cleaned_code))
    
    def _check_character_anomalies(self, code_string: str) -> float:
        """æª¢æŸ¥å­—ç¬¦åˆ†ä½ˆç•°å¸¸"""
        if not code_string:
            return 0.0
        
        char_freq = collections.Counter(code_string)
        total_chars = len(code_string)
        
        # æª¢æŸ¥æ˜¯å¦æœ‰æŸå€‹å­—ç¬¦ä½”æ¯”éé«˜
        max_char_ratio = max(freq / total_chars for freq in char_freq.values())
        
        # æª¢æŸ¥éå¸¸è¦‹ç¨‹å¼èªè¨€å­—ç¬¦çš„æ¯”ä¾‹
        common_code_chars = set('abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789_(){}[];.,=+-*/<>!&|"\'#$%^@`~: \t\n\r')
        unusual_chars = sum(1 for char in code_string if char not in common_code_chars)
        unusual_ratio = unusual_chars / total_chars if total_chars > 0 else 0
        
        # ç¶œåˆç•°å¸¸åˆ†æ•¸
        anomaly_score = max_char_ratio * 0.7 + unusual_ratio * 0.3
        
        return anomaly_score


def check_code_corruption(code_input: str, passed: bool, verbose: bool = True) -> bool:
    """
    ç°¡åŒ–çš„æª¢æŸ¥å‡½æ•¸
    
    Args:
        code_input: å¾…æª¢æŸ¥çš„ç¨‹å¼ç¢¼å­—ä¸²
        verbose: æ˜¯å¦é¡¯ç¤ºè©³ç´°ä¿¡æ¯
    
    Returns:
        bool: True è¡¨ç¤ºå¯èƒ½æå£ï¼ŒFalse è¡¨ç¤ºæ­£å¸¸
    """
    detector = CodeCorruptionDetector()
    result = detector.detect_corruption(code_input, passed, verbose)
    return result['is_corrupted']


def load_jsonl(file_path):
    """
    Load a JSONL file and return a list of dictionaries.
    
    Args:
        file_path (str): Path to the JSONL file.
        
    Returns:
        list: List of dictionaries loaded from the JSONL file.
    """
    with open(file_path, 'r', encoding='utf-8') as f:
        return [json.loads(line) for line in f]

def process_entry(entry):
        code_snippet = entry.get('completion', '')
        passed = entry.get('passed', False)
        return check_code_corruption(code_snippet, passed, verbose=False)

def mp_check_file(file_path: str, verbose: bool = True) -> None:
    # given a file path, use mp method as below, and print the result
    print("=======================================================")
    print(f"Processing file: {file_path}")
    # Load test data
    test_data = load_jsonl(test_data_path)
    # Use multiprocessing to process entries in parallel
    with Pool(processes=cpu_count() - 4) as pool:
        results = list(tqdm(pool.imap(process_entry, test_data), total=len(test_data), desc="Processing entries"))

    # Filter out corrupted codes
    corrupted_codes = [entry for entry, is_corrupted in zip(test_data, results) if is_corrupted]
    # print total data
    print(f"Total entries processed: {len(test_data)}")
    print(f"Total passed codes: {sum(1 for entry in test_data if entry.get('passed', True))}")
    print(f"Total corrupted codes found: {len(corrupted_codes)}")
    print(f"Total compile errors found: {len(test_data) - sum(1 for entry in test_data if entry.get('passed', True)) - len(corrupted_codes)}")

    # Save corrupted codes to a file
    output_path = "corrupted_codes.jsonl"
    with open(output_path, 'w', encoding='utf-8') as f:
        for code in corrupted_codes:
            f.write(json.dumps(code, ensure_ascii=False) + '\n')
        print(f"Corrupted codes saved to: {output_path}")
    print("=======================================================")
    
if __name__ == "__main__":
    test_data_path_list = [
        "/work/u5110390/BenchWeaver/score/pmmeval_exp/en/humaneval-xl/en/mxeval_results.jsonl",
        "/work/u5110390/BenchWeaver/score/pmmeval_exp/en/humaneval-xl/ko/mxeval_results.jsonl",
        "/work/u5110390/BenchWeaver/score/pmmeval_exp/en/humaneval-xl/zh/mxeval_results.jsonl",
        "/work/u5110390/BenchWeaver/score/pmmeval_exp/ko/humaneval-xl/en/mxeval_results.jsonl",
        "/work/u5110390/BenchWeaver/score/pmmeval_exp/ko/humaneval-xl/ko/mxeval_results.jsonl",
        "/work/u5110390/BenchWeaver/score/pmmeval_exp/ko/humaneval-xl/zh/mxeval_results.jsonl",
        "/work/u5110390/BenchWeaver/score/pmmeval_exp/zh/humaneval-xl/en/mxeval_results.jsonl",
        "/work/u5110390/BenchWeaver/score/pmmeval_exp/zh/humaneval-xl/ko/mxeval_results.jsonl",
        "/work/u5110390/BenchWeaver/score/pmmeval_exp/zh/humaneval-xl/zh/mxeval_results.jsonl",
    ]
    for test_data_path in test_data_path_list:
        mp_check_file(test_data_path, verbose=True)
        print()

    