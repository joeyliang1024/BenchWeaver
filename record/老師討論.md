# 與老師開會討論的紀錄
## 12/29
- 向老師報告目前調查到的 Benchmark（英文、繁中）
- 老師的建議：
  - 題目：**Benchmark 整合**：系統化整合不同語言的 Benchmark
    - 韓中對照，延伸到其他語言
    - 選擇語言，製作對應語言和難度的 Benchmark
  - 可能問題：
    1. 如何選擇製作 Benchmark 的方法？
    2. 難度需要對齊
    3. 需要檢查程序，可用高低階模型翻譯
    4. 後續可考慮 Code mixing

## 03/02
教授的建議：
- 翻譯策略與成本考量：
  - 避免直接翻譯資料集，因為成本高且每次新增資料集都需重新翻譯
  - 使用強大的翻譯器將模型輸出翻譯成英文，在英文資料集上測試，以降低成本
  - 對於沒有英文版的資料集，將題目翻譯成模型可理解的語言（如韓文），再將模型輸出翻譯回英文，在英文 Benchmark 上評估
- 建立翻譯 Pipeline：
  - 建立穩定的翻譯方法，專門用於 Benchmark 翻譯，確保翻譯準確性
  - 專有名詞可透過 Prompt Engineering 增強翻譯效果
- 善用現有資源：
  - 利用已有的英文資料集「中文化」或「語言化」資源，與直接在英文資料集上測試的結果比較 (P-MMEval)
  - 考慮使用如 GPT 模型的翻譯工具，OpenAI 提供免費方案
- Benchmark 難度差異：
  - 如果已有釋出 Benchmark，如 TMMLU 或 KMMLU JMMLU Benchmark 難度差異，可以去計算這些指標，評估這些 benchmark 是否有難度差異
- 專案目標與範圍：
  - 測試模型在 CJK（中日韓）及英文上的能力
  - 分析不同情況，如只有英文、只有中文或已有中韓 Benchmark，制定相應測試策略
  - 專案應以目標為導向，避免過度擴展範圍，優先處理最需要的任務
  - 中韓翻譯為優先，可尋求中研院崔智妍博士的協助
- 情境分析：
  - 分析幾種情況：只有英文、只有中文，或已有中韓 Benchmark，制定相應測試策略
  - 如果只有一種語言的 Benchmark，將另一種語言模型的輸出翻譯成現有 Benchmark 的語言進行測試
- 論文核心：
  - 聚焦於如何正確翻譯 Benchmark 題目及模型輸出
  - 加強翻譯準確性，透過 Prompt Engineering 或 Reasoning 等方式，減少人工介入
- 平台建立：
  - 建立一個平台，讓其他人可以使用該平台進行測試
  - 提供經費補助，鼓勵大家提出正式申請，增加影響力
