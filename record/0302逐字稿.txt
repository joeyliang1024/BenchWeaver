教授: 好，那，呃，我這邊有整理一下，呃，就是。

教授: 呃，上次跟老師討論的那，哦，對，有一次會議嗎?

教授: 那，呃，這部分的話，我那個時候是先報告是，呃，我，我去，呃，針對現有的評估這些資料集去做分類，那就是，呃，有分類成包含，呃，與knowledge,然後 language，然後knowledge and exam,然後reasoning,然後，呃，第二BAT就是，呃，instructional發展能力，還有after understanding,然後常文版，safety跟code.

教授: 這幾個分類，這樣。然後..呃..

教授: 不好意思，然後上次還有報告是說我有去整理了英文跟繁中的評估資料集這樣。

教授: 那英文的評估資料集的話就是包含下面的一些很多的現有的benchmark譬如說LAMBDA 3.2 Instruction EVAL跟那些OpenLM, LeverBoard還有Syntel EVAL這些綜合起來然後所以目前的benchmark的話就是各個領域應該都是收集的差不多這樣。

教授: 那就是基本上可以在論文上找到的benchmark在這邊。

教授: 那繁中的話也是去蒐集完繁中的benchmark包含了呃 T2U TIE Bench 跟 TCEVL BitTorque 還有 Bylon Bench,這四個主要的現在臺灣 LN 的呃發展團隊的呃測試一些benchmark這樣。

教授: 那就是包含在這裡。

教授: 那這次的話首先更新的應該是benchmark.收集。那這次的話我是目前有收集完四周年的benchmark這樣呃英文跟中文的話就是繁中的話就是上次有更新過簡中的話就是呃這次有更新這個部分。

教授: 那呃我主要是從 deepseek v3的report還有呃千問2.5的 technique report去找然後這邊的話還多了兩個呃常溫本的資料集這樣。

教授: 那就是有包含了呃cevl, cml 跟 hievl,這三個是屬於呃測驗跟知識測試的這一塊。

教授: 那c3跟cmrc, 這兩個是屬於呃 reasoning的部分。然後cewews, WSC 跟 CCPM,這兩個是屬於 language 的部分。

教授:  CMATS 是他們的數學的測試， Chinese 以為是factual的部分。那剩下三個的話就是 Infinal Bench, Needle Bench 跟 Long Bench的話就是常文本這樣嗯，

教授: 那再來是韓文的話韓文都比較特別就是我去查了他們有一個測試叫做open klm leaderboard然後哎，但是他們這個主要測試就是沒有開源這樣。

教授: 所以就是都是找不到他的他的set的link這樣子。那他們主要測試有ko gpqa那ko的widegrade gsm8k然後EQBench, EVEL那這集的話嗯，我看他們的說明應該是從原始的這些英文資料去做翻譯。

教授: 所以我們，如果要用到這些資料的話應該是我們找一顆模型去翻譯。應該就是 ok 的這樣。

教授: 那剩下的話就是有他們的NAT knowledge然後他們的一些測試的部分。那他們有多了一個Harmless跟Helpfulness的。

教授: 這兩個是說明了屬於Safety的部分。那剩下的部分就是呃其他benchmark的找到資料。那基本上都是屬於呃測試，呃知識跟測驗的部分。

教授: 那除了這個HAE的多了一個understanding的部分這樣。

教授: 那再來就是上次討論過有說到就是呃老師有說上哎就是哎有時額外需要收集額外的簡總跟韓文。那就是剛有報告過我這部分那另外一個就是有說是要去將四種語言的呃測試要去做 alignment 這樣就是確保他們的難度一致這樣。

教授: 所以這次有特別去呃 survey 有關相關的論文這樣嗯，那我這邊先從，呃，比較相關的論文說起好了。

教授: 那第一個的話就是pmmeval,那他們，他就是一個，呃，從現有的英文資料去，呃，利用模型去翻譯成，呃，多語言的。

教授: 平行語料的資料，測試資料集這樣。對，那他這邊的話就是有提供一個，呃，測試就是，呃，測測出目前現有的，呃，LM，那他應該最沒有測到，呃，DC，因為他沒有到那麼新這樣。

教授: 對，那他們這邊測試最好的話就是，呃，紅色的兩顆模型就是千萬的2.

教授: 532比跟千萬2.572比這樣。那，如果要去做翻譯的話呃翻譯最好的話是呃mistral language,呃mistral,這顆第七項，呃large,這顆跟jemba to 27b這一顆這樣那就是在下面這個表格有出現那個分數那上面的話就是 open source 的模型那下面的話則是 closed source 的模型，那他就是有測 gpt 4跟 cloud 3.

教授: 5 這樣嗯，那下表的話就是他去根據模型的大小去做分類這樣那就是呃看分數的話就是呃目前 open source 的模型大概嗯大概50,大概大於50幣以上，其實就跟GPT4呃分數其實沒有差到太多這樣對，那尤其是前文2.

教授: 5其實我是覺得這顆模型是可以拿去做翻譯或是去做一些評估的基準模型就是就是不一定要用到GPT4去做。

教授: 呃，我們 GPT4的API去做。呃，我們現在benchmark的所需要做的翻譯或是評估的部分。

教授: 這樣就是目前可以選擇的替代模型。

教授: 然後另外一個的方式是，呃，因為現在有很多個benchmark,所以他們有提供一個t test的測試方式，那基本上就是會根據，呃，很多個模型的輸出結果，那他會去算他的t test的分數，那基本上就是分數越小的話，就是代表，呃，模型的鑑別度越，模型的鑑別度越高這樣，那就是他找到了一個，他提供了一個方式，這樣。

教授: 然後另外一片的話是 adaption of sort.那這邊的話主要是我會參考他的分類問題的難度。

教授: 這樣那他產生問題的他分類問題難度的話他的步驟是他會先去根據一個問題去給他一個回答。這樣那他會去根據這個問題的回應去他這個回應的話是有去做 Rational,就是產生比較可解釋性的回答。

教授: 這樣。然後他會根據這個解釋性的回答去做他的 Synaptic complexity跟 Synaptic complexity,這兩個部分。

教授: 那第一個部分的話他是去測試他的文字長度去算，他的語意，句法複雜度。

教授: 那他就是，因為這篇文章是有假設說，他的句法複雜度和他的文字長度是層正相關的部分。

教授: 再來就是測量具法負呃語意複雜度的部分。的話他去算他的呃，呃他的一些字數就是經過這些前處理之後的字數這樣然後它的最終的難度的話就是由這兩個算出來的分數去做加總。

教授: 那算出來分數之後它是使用這個分數的變異數去做評估標準。那就是這邊套一個變異數公式之後，那它去取一個區間，就是P等於2分之V,那就是劃分出這個要解難度的話就是ez比normal比它的話就是P比1 ,2P然後比P,這樣那它就是它的分類出它的問題的難度那因為這邊他是去做呃調整他的 channel sort prompting 的方法那所以我們目前參考部分就是這張圖片的前半部分，這樣就只要 Step 2 的分類的這個 Difficulty 的部分這樣那 Step 1 的話就是它會 它的這邊就是解釋，說它如何去產生一個呃 可解釋性的回答， 然後去分類出它去評估出它的難 嗯 問題的難度這樣。

教授: 再來就是呃，我需要去測 alignment 的話就是需要測試的標準呃。

教授: 那這邊就是 a 跟 b 的話就是目前是假設，是兩個資料集的機率分佈。那機率分佈的話就是呃就是在下面這部分會用到，就是會在這邊第5步就是，呃，就是從na除以na的它的那個呃，複雜度的，就譬如說easy, normal， hard的部分，就是得出它的g分布，所以這邊會用到這部分。

教授: 那第一個的話就是去計算 KL divergence.那 KL divergence 的話就是基本上就是測試兩個機率分布的離散程度，這樣那就是越靠近0就代表兩個資料體的呃離散程度越越好呃離散程度越低的那基本上就是這個指標就是越靠近0,越好。

教授: 那JSD的話就是呃他是調整過的KL divergence那基本上就是他有具有對稱性，因為他是有去取1, 2的 A跟取1, 2的B,然後去做呃加權，平，均，這樣那也這樣也是靠越靠近0,越好，這樣那那trade square test的話就是另一種統計學計算divergence的方法，那就是他會去算呃呃，越好，理論上就是呃，越相近的distribution的話，他們就是會有越低的trie square test的分數。

教授: 對，然後P value的話，這邊的P value是從chi square test的話出來。

教授: 那理論上，P value的話就是一個另外一個統計學的指標那就是呃，越高的P value的話就代表兩個，

教授: 兩個機率分布從直接sample出來的機率會越高這樣。所以這個指標是越高，越好。

教授: 最後是一個weather and distance這樣那這個的話就是呃，他的意思是從a的a distribution轉換到b distribution所需要花費的呃一些代價這樣那。

教授: 所以基本上就是如果是這邊的代價是越低的話，代表呃，我越輕易從a distance轉換到 a distribution轉換到b distribution,那基本上也是越低，越好的。

教授: 所以，除了p value以外其他都是越低，越好。

教授: 那這邊的話我提，我這邊是有想出一個 Alignment的方法這樣那呃，第一步的話可能需要去先去選呃選擇我們的測試資料集呃，因為我們剛測試資料集其實在每個領域其實有看到是很多不同的測試資料集。

教授: 所以可能第一步可能選要先用T test或是呃，我們直接選出那個比較知名的資料集去。

教授: 做測試這樣然後第二步的話是需要去將這些資料去做分類的，那分類的話就是有上次會有提到的分類法，譬如說language,然後knowledge and exam,然後reasoning的部分。

教授: 那第三步的話就是去檢查這個language是不是它有對應的語言的資料集那如果是沒有的話，我們就直接去用英文的版本去做反應這樣那我這邊跳英文的話是因為英文的。

學生: 我現在問一下齁。

教授: 對。

學生: 我現在， 你現在停一下。就是我想到一個想法就是你何必去翻資料集呢?

學生: 你就直接叫一個很強的 Translator去把這個，比如說日文模型，把日文的output翻成英文，然後在英文資料集上測，就好了。

教授: 喔..有..也是可以，因為我這邊的話。

學生: ..

學生: 這樣不是成本比較低嗎?

學生: 那我們可以用比如說幾個不同的Translate去翻啊。

教授: 哦，好。

學生: 然後把它平均起來或什麼的。

教授: 嗯，因為我這邊的話。

學生: 你可以去找一個。你可以去找一個有做英文資料集中文化的或是說什麼語言化的然後跟直接在英文資料集上相比是不是有顯著的差異?

學生: 如果沒有的話，說不定就可以用這招。就不用去翻譯資料集了。

教授: 主持人 ，那接下來的部分的話就是，因為第四步的話就是……。因為這邊是假設說譬如說英文有個 mmu的資料集，那中文有個 tml plus的資料集，那就是要去align他們的難度這樣嗯，所以的話這邊的話是採用呃，P呃哦，沒有採用那個上面這個呃，adapt of soul的方法就是剛有報過，就是會請他去產生rationale資料，然後產生rationale,之後去評估他的難度，去算出他的呃，easy，medium，跟hard的分佈，這樣對，那就是這個是第四步的部分。

教授: 那第五步的部分的話就是因為我們其實有拿到 easy hard 跟 normal 的分布了，那我們這邊的話就會去計算它的機率分布，那機率。

教授: 分布的話就是總數除以它的個別的數量，就是它的機率分布那第五步，計算完之後去計算他新的呃，新的新的distribution,會長，怎麼樣子?

教授: 那這邊的話，我們是採簡單的，呃，加權除以二，那就是他的新的級別分布，然後第7步的話就是去計算新的，我們需要去sample新的資料集的數量，這樣，那我就是會跟，那這邊的話就是，呃，幾率分布去乘以呃， Na跟Nb的那個minimum,就是去可以計算出它的新的幾率分布的數量。

教授: 那計算出完，之後就可以去做sampling這樣，最後是去評估它的balancing的分數，這樣。

教授: 那這邊我有測過的話就是看。起來是效果不錯的。就是照這個流程去做sampling資料集的方法的話。

教授: 不知道老師有什麼想法?

學生: 嗯..我覺得往這方向是不錯啦，但是還是要回歸。就是做這件事情的意義在哪裡啦。

學生: 然後還有就是說有沒有什麼比較..就是說到底呃，我剛講嘛就是說你到底是把模型的把題目，比如說把題目翻譯成模型會的語言，然後再把模型的 output翻譯回去。

學生: 這樣這樣測試比較，這樣測試是不是也可以達到你講的這個需求。

教授: 拜拜。可是這樣也不是會多兩部翻譯的步驟嗎?

學生: 對啊，

學生: 那就發的。現在翻譯成本又不高。

學生: 做這個資料集的成本很高欸。

學生: 而且，如果說，用這種翻譯方法的話你有新的背景mark出來，我也不用去再幫他中文化或是幫他什麼哪一種文。

教授: 了解。所以是針對沒有英文版，沒有對應的資料解的話，是這波需要去做其他的，剛剛老師說的那個處理的方法。

教授: 是這樣嗎?

學生: 嗯，這我剛想到了啦。就是說，這樣是不是可以比較就算我用歐模型去做翻譯，我也是比較便宜啊，比起搞這個資料集的多國語言化或是想辦法去對他們做Alignment.

教授: 了解。

教授: 這邊稍微先記錄一下。

學生: 你這邊是當初是講說一個多月前是講說要可以處理CJK跟一個東南亞語言。對不對。

教授: 嗯。

學生: 就是可以測試模型的這種 CJK跟English-

學生: 至少是CJK-跟IngH,這種語言上面的能力嘛， 對不對那，因為大家也都會出自己的啊。

教授: 所以

學生: 有一種measure就是就是你，如果大家已經有出，比如說什麼tmmlu或是什麼 kllu jllu, 這種的，那你就可以去算這些指標，到底這些評估，這些benchmark,到底有沒有難度的差別?

學生: 那如果對於沒有的，就是可能只有英文的，那你可能就可以用這種，這種方式來測，比如說像之前用chapacter,對不對然後不是號稱，說可以學會哪一種語言，對不對?

學生: 嗯，

學生: 要不然只能用英文對話，然後可以換成中文嘛，那你就可以去看說就是加了TV以後的模型，他是不是回答英文的能力就變弱了。

教授: 哦了解。

學生: 就你。你就把題目翻成中文問他，然後他的答案再翻回英文去Benchmark測你可以，你可以，報告很多這種啊。

教授: 呃，這部分我會再去做嘗試。

學生: 就是去找一個比較穩定的，一個翻譯的方法然後就是確保說他在進行測驗的時候。就是翻譯都盡量能夠翻對。

學生: 就是bench, 專門for benchmark翻譯。

教授: 好。

學生: 因為Benchmark他不是，會有一些專有名詞，對不對?

教授: 對對對。

學生: 那有沒有辦法靠Plum Engineering就是把這些專有名詞在在做這個題目之前，把這些專有名詞都搞懂，然後再去做。

學生: 我已經本來可能不會了。

學生: 應該說翻譯，翻譯，可能會翻錯，對不對。

學生: 那你就盡量做到把Benchmark翻對，這樣子好看。有沒有什麼方法可以把Benchmark都翻對?

教授: 了解。

學生: 就發展一個Benchmark的翻譯方法然後讓他盡量誤差，越小，越好。

學生: 然後接下來就是盡量不要去做新的benchmark就利用英文的然後來就是把模型的輸入跟輸出翻成英文然後用原本的英文benchmark去量或是CJK.

學生: 只有C有的話，那就用C為主來量。就不要再去做另外一個語言了。

教授: 好 謝謝。

學生: 那主要優先順序是中韓的。

教授: 嗯，OK。

學生: 因為韓國那個計畫已經下來了。

教授: 嗯，確認一下是繁中，還是減中?

學生:  OK.

教授:  OK.

學生: 翻中跟韓文，但簡中也可以啊。

教授: 嗯。

學生: 那簡中，我們不是有做個翻譯機嗎?

教授: 喔，對。

學生: 但你也不一定要用翻譯機，你可以用那個GPT,這種模型來翻。

教授: 好的。

學生: 然後最近GP..最近那個 OpenAI好像有個免費方案就是你要..你要用，你要分享你的資料，你的這個log,他就可以讓你免費用。

教授: 哦。

學生: 100萬個token.

教授: 嗯。

學生: 這個大家也可以去用。

教授: 好 那我會再跟轉達給其他人這樣。

學生: 嗯。

教授: 好。

學生: 所以你這個上次是不是跟你講說你這個是要for這個跟韓國合作計劃的。

教授: 呃對，上次有說到這部分。

學生: 對 那你可能要再收斂一下，因為你這個東西太多了。

教授: 嗯。

學生: 你可能就要有幾你要分幾種，幾種 benchmark 的問題就是有只有英文或只有中文，然後或者是或者是已經有兩種語言。

學生: 的已經有中韓，的那要已經有中韓。就是要去對比他們的難度，對不對?

教授: 對。

學生: 如果，如果那個好只有其中一個話，那就要把另外一個模型的能力，比如說只有中文， 那韓文那個就要把他的upload翻成中文然後在中文上面做。

學生: 如果說只有韓文的話， 那中文就要翻成韓文， 在韓文上面做。

教授: 對啊。

學生: 反正你要去分析。有幾種情況了，好不好。

教授: 呃， 等一下 老師，我確認一下喔，因為剛老師說

學生: 然後我跟你講就是我， 我跟你講就是我們是目的導向。

學生: 就是你不要去做一些計畫用不到的東西。啊，我們是目的導向。

教授: 謝謝。

學生: 一展開很多東西，

學生: 就是說很完整，但是其實計劃根本就用不到。

教授:  OK.

學生: 而且你也做不完。所以我跟你講，說你要聚焦從最需要的做到有時間再去做那些。

教授: 謝謝。

學生: 不一定又有得到。

教授: 哦， 瞄準那老師。我可以確認一件事情就是剛有說到就是如果是只有中文的benchmark的話那韓文模型要測試，是要先將它的輸出翻譯成中文，再去做測試。

教授: 那欸那我們它可是這個韓文模型不是只吃韓文的輸入嗎那這樣不是還是要翻譯?

學生: 沒有輸入，你要翻啊。你要把你的題目翻成韓文去問它。

教授: 對，那為什麼不直接翻譯資料集就可以?對應出它的..

學生: 不要去翻譯資料集，因為資料集那個工程很大，你每出一個新的你就要翻譯一次。欸，這不是很麻煩嗎?

教授: 哦， 懂了， 懂了， 懂了， 懂了。

學生: 就是資料集會，一直新增。啊，我現在在想一個比較比較彈性現在。

教授: 是一個Pipeline,這樣嗎。

學生: 對對。我們就建制一個Pipeline.

教授: 就是我懂了，我懂了這意思了，不好意思。

學生: 我，

教授: 剛，

學生: 測試多那你這樣是不是有新的進來?你也根本不用。你也根本不用去去翻譯資料集。

教授:  ok ok, 我，我，我連接。

學生: 對對，對。然後你，你現在要變的。

學生: 你現在的焦點變成說如何把Benchmark翻譯，對，但是其實，因為Benchmark題目不多嘛，而且他有些背景知識對不對那你就是想辦法讓背景知識那讓這個題目翻，對你要，你現在的論文核心變成是如何讓 Benchmark題目翻，對還有，把那個模型 output 犯，對。

學生: 然後你這個翻譯就加強這邊就好。而且最好是透過 Plumber Engineer 用你的方式或是透過 reasoning 這種 test time 的 scaling 的方式，你就不用還要在那邊，在那邊 fine tune 什麼。

教授: 的嗯。

學生: 了解嗎?

教授: 嗯，我理解了。

學生: 嗯，這樣就都不用去花到什麼人工，什麼的那，你韓文的話你可以找。

學生: 我有一個博士後，中文就是在中研院的。

教授: 嗯..

學生: 可以，崔智妍。

教授: 好你。

學生: 問DH組。 請他們問。請他們給你崔博士的聯絡方式。

教授: 嗯，嗯，嗯，好。

學生: 你韓文就可以找他。那我們優先就是做中韓像。我覺得說其實我們臺灣也，除了一些本土化的那種，說不定我們可以這個東西做出來。

學生: 以後我們就做個平臺讓人家來測反正我們也有一些經費，就是說，他如果提出正式的申請，我們就幫他撤。

教授: 哦。

學生: 這樣我們就會有影響力。就比那個什麼，你知道哪一個單位你在錄影，我不要罵了。

學生: 對這個，

學生: 把錄影關掉好了，你看錄影關掉。我就敢罵了。

教授: 我看一下。

